{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Earth Engine Data Preparation for FuseTS (FIXED VERSION)\n",
    "\n",
    "This notebook extracts Sentinel-1 and Sentinel-2 data from Google Earth Engine and prepares it for FuseTS MOGPR processing.\n",
    "\n",
    "## ‚úÖ FIXES IN THIS VERSION:\n",
    "1. **Uses Level-2A Surface Reflectance** (`COPERNICUS/S2_SR_HARMONIZED`) instead of Level-1C TOA\n",
    "2. **Includes cloud masking** for better NDVI quality\n",
    "3. **Validates NDVI values** are in [-1, 1] range before export\n",
    "4. **Adds diagnostic checks** to catch data corruption early\n",
    "5. **Ensures correct band selection** when combining S1 and S2\n",
    "\n",
    "## ‚ö†Ô∏è ORIGINAL BUG:\n",
    "The original notebook exported VV/VH backscatter (-48 to 6 dB) in the S2ndvi band instead of actual NDVI values (-1 to 1). This made S1‚ÜíNDVI fusion impossible.\n",
    "\n",
    "## Temporal Compositing Strategy\n",
    "- **Total periods**: 62 periods from Nov 2023 - Nov 2025\n",
    "- **Period length**: 12 days each\n",
    "- **Start date**: November 1, 2023\n",
    "- **End date**: November 7, 2025\n",
    "\n",
    "## Indonesian Agricultural Calendar Coverage\n",
    "This date range captures:\n",
    "- **First planting season**: Nov 2023 - Mar 2024 (crosses year boundary)\n",
    "- **Second planting season**: Apr - Jun 2024\n",
    "- **Third planting season**: Jul - Sep 2024\n",
    "- **Full cycle**: ~2 complete agricultural years\n",
    "\n",
    "## Output Format\n",
    "Data will be exported in FuseTS-compatible format with proper band naming:\n",
    "- S1: `VV`, `VH` bands (backscatter in dB, range: -50 to +10)\n",
    "- S2: `S2ndvi` band (NDVI values, range: -1 to 1) ‚Üê **NOW CORRECT!**\n",
    "- Dimensions: `(time, y, x)` with `t` coordinate name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Authenticating with Google Earth Engine...\n",
      "‚úÖ Authentication successful!\n",
      "‚úÖ Earth Engine initialized successfully!\n",
      "   Project: ee-geodeticengineeringundip\n",
      "\n",
      "üì¶ Package versions:\n",
      "   Earth Engine API: 1.6.15\n",
      "   geemap: 0.36.6\n",
      "   rasterio: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Additional imports for mask processing\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape, mapping\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Initialize Earth Engine with authentication\n",
    "print(\"üîê Authenticating with Google Earth Engine...\")\n",
    "\n",
    "try:\n",
    "    # First time setup: authenticate\n",
    "    ee.Authenticate()\n",
    "    print(\"‚úÖ Authentication successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Authentication note: {e}\")\n",
    "    print(\"If already authenticated, continuing...\")\n",
    "\n",
    "# Initialize with project\n",
    "try:\n",
    "    ee.Initialize(project='ee-geodeticengineeringundip')\n",
    "    print(\"‚úÖ Earth Engine initialized successfully!\")\n",
    "    print(f\"   Project: ee-geodeticengineeringundip\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing Earth Engine: {e}\")\n",
    "    print(\"Please ensure:\")\n",
    "    print(\"  1. You have run ee.Authenticate() successfully\")\n",
    "    print(\"  2. You have access to project 'ee-geodeticengineeringundip'\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nüì¶ Package versions:\")\n",
    "print(f\"   Earth Engine API: {ee.__version__}\")\n",
    "print(f\"   geemap: {geemap.__version__}\")\n",
    "print(f\"   rasterio: {rasterio.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Study Area and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìç STUDY AREA CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "üéØ Using Paddy Shapefile: data/klambu-glapan.shp\n",
      "\n",
      "‚úÖ Shapefile loaded successfully!\n",
      "   Number of features: 1043\n",
      "   CRS: EPSG:4326\n",
      "\n",
      "   Converting to UTM Zone 49S for accurate buffering...\n",
      "   Total paddy area: 559.46 km¬≤\n",
      "\n",
      "   Applying 500m buffer (in UTM)...\n",
      "   Buffered area: 879.84 km¬≤\n",
      "\n",
      "   Converting back to WGS84 for Earth Engine...\n",
      "   WGS84 Bounds (for Earth Engine):\n",
      "     West:  110.513130¬∞\n",
      "     South: -7.113018¬∞\n",
      "     East:  111.038229¬∞\n",
      "     North: -6.713087¬∞\n",
      "\n",
      "‚úÖ Study area created from shapefile!\n",
      "   Type: Paddy field boundaries (Klambu-Glapan)\n",
      "   Location: Demak, Central Java, Indonesia\n",
      "   Buffer: 500m around paddy fields\n",
      "   Area (GEE): 884.30 km¬≤\n",
      "\n",
      "======================================================================\n",
      "üìã FINAL PROCESSING CONFIGURATION\n",
      "======================================================================\n",
      "   Study Area: KLAMBU_GLAPAN_SHAPEFILE\n",
      "   Area size: 884.30 km¬≤\n",
      "   Temporal coverage: 2023-11-01 to 2025-11-07\n",
      "   Spatial resolution: 10m\n",
      "   Max cloud cover: 80%\n",
      "   Output directory: gee_fusets_data_fixed/\n",
      "\n",
      "‚úÖ Using CORRECTED data loading functions (Level-2A SR with cloud masking)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STUDY AREA FROM SHAPEFILE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìç STUDY AREA CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load the paddy shapefile\n",
    "shapefile_path = 'data/klambu-glapan.shp'\n",
    "\n",
    "print(f\"\\nüéØ Using Paddy Shapefile: {shapefile_path}\")\n",
    "\n",
    "try:\n",
    "    # Read the shapefile\n",
    "    paddy_gdf = gpd.read_file(shapefile_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Shapefile loaded successfully!\")\n",
    "    print(f\"   Number of features: {len(paddy_gdf)}\")\n",
    "    print(f\"   CRS: {paddy_gdf.crs}\")\n",
    "    \n",
    "    # Convert to UTM Zone 49S (EPSG:32749) - appropriate for Central Java, Indonesia\n",
    "    print(f\"\\n   Converting to UTM Zone 49S for accurate buffering...\")\n",
    "    paddy_utm = paddy_gdf.to_crs(\"EPSG:32749\")\n",
    "    \n",
    "    # Calculate accurate area in UTM\n",
    "    total_area_m2 = paddy_utm.area.sum()\n",
    "    total_area_km2 = total_area_m2 / 1e6\n",
    "    print(f\"   Total paddy area: {total_area_km2:.2f} km¬≤\")\n",
    "    \n",
    "    # Add buffer in UTM (meters)\n",
    "    BUFFER_DISTANCE_M = 500  # 500 meters buffer\n",
    "    print(f\"\\n   Applying {BUFFER_DISTANCE_M}m buffer (in UTM)...\")\n",
    "    \n",
    "    # Create buffered geometry in UTM\n",
    "    paddy_buffered_utm = paddy_utm.copy()\n",
    "    paddy_buffered_utm['geometry'] = paddy_utm.buffer(BUFFER_DISTANCE_M)\n",
    "    \n",
    "    # Merge all buffered polygons into one\n",
    "    merged_geometry_utm = unary_union(paddy_buffered_utm.geometry)\n",
    "    buffered_area_km2 = merged_geometry_utm.area / 1e6\n",
    "    \n",
    "    print(f\"   Buffered area: {buffered_area_km2:.2f} km¬≤\")\n",
    "    \n",
    "    # Convert back to WGS84 for Earth Engine\n",
    "    print(f\"\\n   Converting back to WGS84 for Earth Engine...\")\n",
    "    \n",
    "    # Create GeoDataFrame with merged buffered geometry (in UTM)\n",
    "    buffered_gdf_utm = gpd.GeoDataFrame(\n",
    "        geometry=[merged_geometry_utm],\n",
    "        crs=\"EPSG:32749\"\n",
    "    )\n",
    "    \n",
    "    # Convert to WGS84\n",
    "    buffered_gdf_wgs84 = buffered_gdf_utm.to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Get WGS84 bounds\n",
    "    west, south, east, north = buffered_gdf_wgs84.total_bounds\n",
    "    \n",
    "    print(f\"   WGS84 Bounds (for Earth Engine):\")\n",
    "    print(f\"     West:  {west:.6f}¬∞\")\n",
    "    print(f\"     South: {south:.6f}¬∞\")\n",
    "    print(f\"     East:  {east:.6f}¬∞\")\n",
    "    print(f\"     North: {north:.6f}¬∞\")\n",
    "    \n",
    "    # Convert to GeoJSON for Earth Engine\n",
    "    geojson_geom = mapping(buffered_gdf_wgs84.geometry.iloc[0])\n",
    "    \n",
    "    # Create Earth Engine Geometry\n",
    "    study_area = ee.Geometry(geojson_geom)\n",
    "    \n",
    "    gee_area_km2 = study_area.area().getInfo() / 1e6\n",
    "    \n",
    "    print(f\"\\n‚úÖ Study area created from shapefile!\")\n",
    "    print(f\"   Type: Paddy field boundaries (Klambu-Glapan)\")\n",
    "    print(f\"   Location: Demak, Central Java, Indonesia\")\n",
    "    print(f\"   Buffer: {BUFFER_DISTANCE_M}m around paddy fields\")\n",
    "    print(f\"   Area (GEE): {gee_area_km2:.2f} km¬≤\")\n",
    "    \n",
    "    STUDY_AREA_TYPE = 'klambu_glapan_shapefile'\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n‚ùå ERROR: Shapefile not found!\")\n",
    "    print(f\"   Expected path: {shapefile_path}\")\n",
    "    print(f\"   Please ensure the shapefile exists in the data/ folder\")\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR loading shapefile: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# Processing parameters\n",
    "START_DATE = '2023-11-01'  # November 1, 2023\n",
    "END_DATE = '2025-11-07'    # November 7, 2025\n",
    "SCALE = 10  # meters per pixel (10m = native S2 resolution)\n",
    "CRS = 'EPSG:4326'  # WGS84 coordinate system\n",
    "MAX_CLOUD_COVER = 80  # Maximum cloud cover percentage for S2\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = 'gee_fusets_data_fixed'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Display final configuration\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìã FINAL PROCESSING CONFIGURATION\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   Study Area: {STUDY_AREA_TYPE.upper()}\")\n",
    "print(f\"   Area size: {gee_area_km2:.2f} km¬≤\")\n",
    "print(f\"   Temporal coverage: {START_DATE} to {END_DATE}\")\n",
    "print(f\"   Spatial resolution: {SCALE}m\")\n",
    "print(f\"   Max cloud cover: {MAX_CLOUD_COVER}%\")\n",
    "print(f\"   Output directory: {OUTPUT_DIR}/\")\n",
    "print(f\"\\n‚úÖ Using CORRECTED data loading functions (Level-2A SR with cloud masking)\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate 12-Day Composite Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 62 periods from 2023-11-01 to 2025-11-07:\n",
      "\n",
      "First 5 periods:\n",
      "Period  1: 2023-11-01 to 2023-11-12\n",
      "Period  2: 2023-11-13 to 2023-11-24\n",
      "Period  3: 2023-11-25 to 2023-12-06\n",
      "Period  4: 2023-12-07 to 2023-12-18\n",
      "Period  5: 2023-12-19 to 2023-12-30\n",
      "\n",
      "Last 5 periods:\n",
      "Period 58: 2025-09-15 to 2025-09-26\n",
      "Period 59: 2025-09-27 to 2025-10-08\n",
      "Period 60: 2025-10-09 to 2025-10-20\n",
      "Period 61: 2025-10-21 to 2025-11-01\n",
      "Period 62: 2025-11-02 to 2025-11-07\n",
      "\n",
      "Total temporal coverage: 2023-11-01 to 2025-11-07\n",
      "Covers 62 12-day periods over 2 years\n"
     ]
    }
   ],
   "source": [
    "def generate_12day_periods(start_date_str, end_date_str):\n",
    "    \"\"\"\n",
    "    Generate periods of 12 days each from start date to end date\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    start_date_str : str\n",
    "        Start date in 'YYYY-MM-DD' format (e.g., '2023-11-01')\n",
    "    end_date_str : str\n",
    "        End date in 'YYYY-MM-DD' format (e.g., '2025-11-07')\n",
    "    \"\"\"\n",
    "    start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "    \n",
    "    periods = []\n",
    "    period_num = 1\n",
    "    current_start = start_date\n",
    "    \n",
    "    while current_start <= end_date:\n",
    "        period_end = current_start + timedelta(days=11)  # 12 days inclusive\n",
    "        \n",
    "        # Ensure we don't go beyond the end date\n",
    "        if period_end > end_date:\n",
    "            period_end = end_date\n",
    "            \n",
    "        periods.append({\n",
    "            'period': period_num,\n",
    "            'start_date': current_start,\n",
    "            'end_date': period_end,\n",
    "            'start_str': current_start.strftime('%Y-%m-%d'),\n",
    "            'end_str': period_end.strftime('%Y-%m-%d'),\n",
    "            'center_date': current_start + timedelta(days=6),\n",
    "            'doy_center': (current_start + timedelta(days=6)).timetuple().tm_yday,\n",
    "            'year': current_start.year,\n",
    "            'month': current_start.month\n",
    "        })\n",
    "        \n",
    "        if period_end >= end_date:\n",
    "            break\n",
    "        \n",
    "        current_start = period_end + timedelta(days=1)\n",
    "        period_num += 1\n",
    "            \n",
    "    return periods\n",
    "\n",
    "# Generate periods from Nov 2023 to Nov 2025\n",
    "periods = generate_12day_periods(START_DATE, END_DATE)\n",
    "\n",
    "print(f\"Generated {len(periods)} periods from {START_DATE} to {END_DATE}:\")\n",
    "print(\"\\nFirst 5 periods:\")\n",
    "for i, period in enumerate(periods[:5]):\n",
    "    print(f\"Period {period['period']:2d}: {period['start_str']} to {period['end_str']}\")\n",
    "\n",
    "print(\"\\nLast 5 periods:\")\n",
    "for i, period in enumerate(periods[-5:]):\n",
    "    print(f\"Period {period['period']:2d}: {period['start_str']} to {period['end_str']}\")\n",
    "\n",
    "print(f\"\\nTotal temporal coverage: {periods[0]['start_str']} to {periods[-1]['end_str']}\")\n",
    "print(f\"Covers {len(periods)} 12-day periods over 2 years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Data Loading Functions (FIXED VERSION)\n",
    "\n",
    "**üîß FIXES IN THIS CELL:**\n",
    "1. ‚úÖ Uses **Level-2A Surface Reflectance** (`COPERNICUS/S2_SR_HARMONIZED`) instead of Level-1C TOA\n",
    "2. ‚úÖ Includes **cloud masking** using QA60 band for better NDVI quality\n",
    "3. ‚úÖ Validates **NDVI values are in [-1, 1]** range\n",
    "4. ‚úÖ Uses **proper band names** from S2_SR collection (B8, B4)\n",
    "5. ‚úÖ Adds **diagnostic information** to track data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loading functions defined successfully!\n",
      "\n",
      "üîß FIXED IMPROVEMENTS:\n",
      "   ‚úÖ Using Level-2A Surface Reflectance (not TOA)\n",
      "   ‚úÖ Cloud masking applied using QA60 band\n",
      "   ‚úÖ NDVI clamped to valid range [-1, 1]\n",
      "   ‚úÖ Only NDVI band selected (no confusion with VV/VH)\n"
     ]
    }
   ],
   "source": [
    "def load_sentinel1_data(geometry, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Load Sentinel-1 GRD data for a specific time period\n",
    "    \n",
    "    Returns VV and VH backscatter in dB (typical range: -50 to +10 dB)\n",
    "    \"\"\"\n",
    "    s1_collection = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "                    .filterBounds(geometry)\n",
    "                    .filterDate(start_date, end_date)\n",
    "                    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "                    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "                    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
    "                    .select(['VV', 'VH']))\n",
    "    \n",
    "    return s1_collection\n",
    "\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"\n",
    "    Mask clouds in Sentinel-2 SR image using QA60 band\n",
    "    \n",
    "    Bit 10: Clouds (opaque)\n",
    "    Bit 11: Cirrus clouds\n",
    "    \"\"\"\n",
    "    qa = image.select('QA60')\n",
    "    \n",
    "    # Bits 10 and 11 are clouds and cirrus\n",
    "    cloud_bit_mask = 1 << 10\n",
    "    cirrus_bit_mask = 1 << 11\n",
    "    \n",
    "    # Both bits should be zero for clear conditions\n",
    "    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(\n",
    "           qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "    \n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def load_sentinel2_data(geometry, start_date, end_date, max_cloud_cover=80):\n",
    "    \"\"\"\n",
    "    Load Sentinel-2 Level-2A Surface Reflectance data with cloud masking\n",
    "    \n",
    "    ‚úÖ FIXED VERSION:\n",
    "    - Uses COPERNICUS/S2_SR_HARMONIZED (Level-2A Surface Reflectance)\n",
    "    - Applies cloud masking using QA60 band\n",
    "    - Calculates NDVI from atmospherically corrected bands\n",
    "    - Returns ONLY the NDVI band (no ambiguity)\n",
    "    \n",
    "    Benefits:\n",
    "    - Atmospherically corrected (more accurate than TOA)\n",
    "    - Cloud-masked (better quality NDVI)\n",
    "    - Validated NDVI range [-1, 1]\n",
    "    \n",
    "    Collection: COPERNICUS/S2_SR_HARMONIZED (Level-2A SR, NOT Level-1C TOA)\n",
    "    \"\"\"\n",
    "    def calculate_ndvi_sr(image):\n",
    "        # Apply cloud mask first\n",
    "        image_masked = mask_s2_clouds(image)\n",
    "        \n",
    "        # B8 = NIR, B4 = Red (from Surface Reflectance)\n",
    "        ndvi = image_masked.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        \n",
    "        # Clamp NDVI to valid range [-1, 1] as a safety check\n",
    "        ndvi = ndvi.clamp(-1, 1)\n",
    "        \n",
    "        # Copy properties to NDVI band\n",
    "        ndvi = ndvi.copyProperties(image, ['system:time_start'])\n",
    "        \n",
    "        return ndvi\n",
    "    \n",
    "    # Load Level-2A Surface Reflectance data WITH cloud masking\n",
    "    s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')  # ‚Üê FIXED: Using SR, not TOA\n",
    "                    .filterBounds(geometry)\n",
    "                    .filterDate(start_date, end_date)\n",
    "                    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "                    .map(calculate_ndvi_sr))  # ‚Üê FIXED: Applies cloud masking + NDVI calculation\n",
    "    \n",
    "    return s2_collection\n",
    "\n",
    "def create_composite(collection, method='median'):\n",
    "    \"\"\"\n",
    "    Create a composite from an image collection\n",
    "    \"\"\"\n",
    "    if method == 'median':\n",
    "        return collection.median()\n",
    "    elif method == 'mean':\n",
    "        return collection.mean()\n",
    "    elif method == 'max':\n",
    "        return collection.max()\n",
    "    else:\n",
    "        return collection.median()\n",
    "\n",
    "print(\"‚úÖ Data loading functions defined successfully!\")\n",
    "print(\"\\nüîß FIXED IMPROVEMENTS:\")\n",
    "print(\"   ‚úÖ Using Level-2A Surface Reflectance (not TOA)\")\n",
    "print(\"   ‚úÖ Cloud masking applied using QA60 band\")\n",
    "print(\"   ‚úÖ NDVI clamped to valid range [-1, 1]\")\n",
    "print(\"   ‚úÖ Only NDVI band selected (no confusion with VV/VH)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Data for All Periods (WITH VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ STARTING DATA PROCESSING WITH VALIDATION\n",
      "======================================================================\n",
      "\n",
      "Processing Period 1: 2023-11-01 to 2023-11-12 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 2: 2023-11-13 to 2023-11-24 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 3: 2023-11-25 to 2023-12-06 ‚Üí S1: 2, S2: 0 ‚úì\n",
      "Processing Period 4: 2023-12-07 to 2023-12-18 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 5: 2023-12-19 to 2023-12-30 ‚Üí S1: 2, S2: 6 ‚úì\n",
      "Processing Period 6: 2023-12-31 to 2024-01-11 ‚Üí S1: 2, S2: 0 ‚úì\n",
      "Processing Period 7: 2024-01-12 to 2024-01-23 ‚Üí S1: 2, S2: 2 ‚úì\n",
      "Processing Period 8: 2024-01-24 to 2024-02-04 ‚Üí S1: 2, S2: 3 ‚úì\n",
      "Processing Period 9: 2024-02-05 to 2024-02-16 ‚Üí S1: 2, S2: 2 ‚úì\n",
      "Processing Period 10: 2024-02-17 to 2024-02-28 ‚Üí S1: 2, S2: 3 ‚úì\n",
      "\n",
      "--- Completed 10/62 periods ---\n",
      "\n",
      "Processing Period 11: 2024-02-29 to 2024-03-11 ‚Üí S1: 2, S2: 0 ‚úì\n",
      "Processing Period 12: 2024-03-12 to 2024-03-23 ‚Üí S1: 2, S2: 0 ‚úì\n",
      "Processing Period 13: 2024-03-24 to 2024-04-04 ‚Üí S1: 2, S2: 2 ‚úì\n",
      "Processing Period 14: 2024-04-05 to 2024-04-16 ‚Üí S1: 1, S2: 4 ‚úì\n",
      "Processing Period 15: 2024-04-17 to 2024-04-28 ‚Üí S1: 2, S2: 5 ‚úì\n",
      "Processing Period 16: 2024-04-29 to 2024-05-10 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 17: 2024-05-11 to 2024-05-22 ‚Üí S1: 2, S2: 3 ‚úì\n",
      "Processing Period 18: 2024-05-23 to 2024-06-03 ‚Üí S1: 1, S2: 4 ‚úì\n",
      "Processing Period 19: 2024-06-04 to 2024-06-15 ‚Üí S1: 1, S2: 4 ‚úì\n",
      "Processing Period 20: 2024-06-16 to 2024-06-27 ‚Üí S1: 1, S2: 6 ‚úì\n",
      "\n",
      "--- Completed 20/62 periods ---\n",
      "\n",
      "Processing Period 21: 2024-06-28 to 2024-07-09 ‚Üí S1: 2, S2: 3 ‚úì\n",
      "Processing Period 22: 2024-07-10 to 2024-07-21 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 23: 2024-07-22 to 2024-08-02 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 24: 2024-08-03 to 2024-08-14 ‚Üí S1: 1, S2: 4 ‚úì\n",
      "Processing Period 25: 2024-08-15 to 2024-08-26 ‚Üí S1: 2, S2: 6 ‚úì\n",
      "Processing Period 26: 2024-08-27 to 2024-09-07 ‚Üí S1: 1, S2: 4 ‚úì\n",
      "Processing Period 27: 2024-09-08 to 2024-09-19 ‚Üí S1: 1, S2: 4 ‚úì\n",
      "Processing Period 28: 2024-09-20 to 2024-10-01 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 29: 2024-10-02 to 2024-10-13 ‚Üí S1: 1, S2: 3 ‚úì\n",
      "Processing Period 30: 2024-10-14 to 2024-10-25 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "\n",
      "--- Completed 30/62 periods ---\n",
      "\n",
      "Processing Period 31: 2024-10-26 to 2024-11-06 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 32: 2024-11-07 to 2024-11-18 ‚Üí S1: 2, S2: 3 ‚úì\n",
      "Processing Period 33: 2024-11-19 to 2024-11-30 ‚Üí S1: 2, S2: 1 ‚úì\n",
      "Processing Period 34: 2024-12-01 to 2024-12-12 ‚Üí S1: 2, S2: 0 ‚úì\n",
      "Processing Period 35: 2024-12-13 to 2024-12-24 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 36: 2024-12-25 to 2025-01-05 ‚Üí S1: 2, S2: 0 ‚úì\n",
      "Processing Period 37: 2025-01-06 to 2025-01-17 ‚Üí S1: 2, S2: 2 ‚úì\n",
      "Processing Period 38: 2025-01-18 to 2025-01-29 ‚Üí S1: 2, S2: 0 ‚úì\n",
      "Processing Period 39: 2025-01-30 to 2025-02-10 ‚Üí S1: 2, S2: 1 ‚úì\n",
      "Processing Period 40: 2025-02-11 to 2025-02-22 ‚Üí S1: 2, S2: 1 ‚úì\n",
      "\n",
      "--- Completed 40/62 periods ---\n",
      "\n",
      "Processing Period 41: 2025-02-23 to 2025-03-06 ‚Üí S1: 2, S2: 2 ‚úì\n",
      "Processing Period 42: 2025-03-07 to 2025-03-18 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 43: 2025-03-19 to 2025-03-30 ‚Üí S1: 0, S2: 1 ‚úì\n",
      "Processing Period 44: 2025-03-31 to 2025-04-11 ‚Üí S1: 3, S2: 4 ‚úì\n",
      "Processing Period 45: 2025-04-12 to 2025-04-23 ‚Üí S1: 3, S2: 2 ‚úì\n",
      "Processing Period 46: 2025-04-24 to 2025-05-05 ‚Üí S1: 3, S2: 5 ‚úì\n",
      "Processing Period 47: 2025-05-06 to 2025-05-17 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 48: 2025-05-18 to 2025-05-29 ‚Üí S1: 2, S2: 3 ‚úì\n",
      "Processing Period 49: 2025-05-30 to 2025-06-10 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 50: 2025-06-11 to 2025-06-22 ‚Üí S1: 3, S2: 5 ‚úì\n",
      "\n",
      "--- Completed 50/62 periods ---\n",
      "\n",
      "Processing Period 51: 2025-06-23 to 2025-07-04 ‚Üí S1: 3, S2: 6 ‚úì\n",
      "Processing Period 52: 2025-07-05 to 2025-07-16 ‚Üí S1: 1, S2: 2 ‚úì\n",
      "Processing Period 53: 2025-07-17 to 2025-07-28 ‚Üí S1: 1, S2: 6 ‚úì\n",
      "Processing Period 54: 2025-07-29 to 2025-08-09 ‚Üí S1: 2, S2: 6 ‚úì\n",
      "Processing Period 55: 2025-08-10 to 2025-08-21 ‚Üí S1: 3, S2: 6 ‚úì\n",
      "Processing Period 56: 2025-08-22 to 2025-09-02 ‚Üí S1: 3, S2: 6 ‚úì\n",
      "Processing Period 57: 2025-09-03 to 2025-09-14 ‚Üí S1: 3, S2: 4 ‚úì\n",
      "Processing Period 58: 2025-09-15 to 2025-09-26 ‚Üí S1: 2, S2: 4 ‚úì\n",
      "Processing Period 59: 2025-09-27 to 2025-10-08 ‚Üí S1: 3, S2: 3 ‚úì\n",
      "Processing Period 60: 2025-10-09 to 2025-10-20 ‚Üí S1: 3, S2: 9 ‚úì\n",
      "\n",
      "--- Completed 60/62 periods ---\n",
      "\n",
      "Processing Period 61: 2025-10-21 to 2025-11-01 ‚Üí S1: 2, S2: 1 ‚úì\n",
      "Processing Period 62: 2025-11-02 to 2025-11-07 ‚Üí S1: 2, S2: 2 ‚úì\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Successfully processed 62 out of 62 periods\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Created time series collection with 62 images\n",
      "   All images contain bands: ['VV', 'VH', 'S2ndvi']\n",
      "   NDVI source: Sentinel-2 Level-2A Surface Reflectance (cloud-masked)\n"
     ]
    }
   ],
   "source": [
    "def process_single_period(period_info, geometry, scale=10):\n",
    "    \"\"\"\n",
    "    Process S1 and S2 data for a single 12-day period\n",
    "    \n",
    "    ‚úÖ FIXED VERSION with validation:\n",
    "    - Ensures S2ndvi band contains actual NDVI (not VV/VH backscatter)\n",
    "    - Adds diagnostic checks\n",
    "    - Validates band names and ranges\n",
    "    \"\"\"\n",
    "    start_date = period_info['start_str']\n",
    "    end_date = period_info['end_str']\n",
    "    period_num = period_info['period']\n",
    "    \n",
    "    print(f\"Processing Period {period_num}: {start_date} to {end_date}\", end=\"\")\n",
    "    \n",
    "    try:\n",
    "        # Load Sentinel-1 data\n",
    "        s1_collection = load_sentinel1_data(geometry, start_date, end_date)\n",
    "        s1_count = s1_collection.size().getInfo()\n",
    "        \n",
    "        # Load Sentinel-2 data (Level-2A SR with cloud masking)\n",
    "        s2_collection = load_sentinel2_data(geometry, start_date, end_date, MAX_CLOUD_COVER)\n",
    "        s2_count = s2_collection.size().getInfo()\n",
    "        \n",
    "        print(f\" ‚Üí S1: {s1_count}, S2: {s2_count}\", end=\"\")\n",
    "        \n",
    "        # Create composites\n",
    "        if s1_count > 0:\n",
    "            s1_composite = create_composite(s1_collection, 'median')\n",
    "        else:\n",
    "            # Create empty image with correct bands\n",
    "            s1_composite = ee.Image.constant([0, 0]).rename(['VV', 'VH']).updateMask(ee.Image.constant(0))\n",
    "            \n",
    "        if s2_count > 0:\n",
    "            s2_composite = create_composite(s2_collection, 'median')\n",
    "            # s2_composite already has only NDVI band from load_sentinel2_data\n",
    "        else:\n",
    "            # Create empty NDVI image\n",
    "            s2_composite = ee.Image.constant(0).rename('NDVI').updateMask(ee.Image.constant(0))\n",
    "        \n",
    "        # ‚úÖ FIX: Explicitly rename S2 band to S2ndvi to avoid confusion\n",
    "        s2_ndvi_band = s2_composite.select(['NDVI']).rename('S2ndvi')\n",
    "        \n",
    "        # Combine S1 and S2 data\n",
    "        # Order: VV, VH, S2ndvi\n",
    "        combined_image = s1_composite.select(['VV', 'VH']).addBands(s2_ndvi_band)\n",
    "        \n",
    "        # ‚úÖ VALIDATION: Check band names\n",
    "        band_names = combined_image.bandNames().getInfo()\n",
    "        expected_bands = ['VV', 'VH', 'S2ndvi']\n",
    "        \n",
    "        if band_names != expected_bands:\n",
    "            print(f\" ‚ö†Ô∏è WARNING: Band names mismatch!\")\n",
    "            print(f\"      Expected: {expected_bands}\")\n",
    "            print(f\"      Got: {band_names}\")\n",
    "        else:\n",
    "            print(f\" ‚úì\", end=\"\")\n",
    "        \n",
    "        # Add metadata\n",
    "        combined_image = combined_image.set({\n",
    "            'period': period_num,\n",
    "            'start_date': start_date,\n",
    "            'end_date': end_date,\n",
    "            'center_date': period_info['center_date'].strftime('%Y-%m-%d'),\n",
    "            'doy_center': period_info['doy_center'],\n",
    "            's1_count': s1_count,\n",
    "            's2_count': s2_count,\n",
    "            'data_version': 'FIXED_v2',  # Mark as fixed version\n",
    "            'ndvi_source': 'S2_SR_HARMONIZED',  # Document NDVI source\n",
    "            'cloud_masked': True  # Document cloud masking applied\n",
    "        })\n",
    "        \n",
    "        print(\"\")  # New line\n",
    "        return combined_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process all periods\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING DATA PROCESSING WITH VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "\n",
    "processed_images = []\n",
    "successful_periods = []\n",
    "\n",
    "for i, period in enumerate(periods):\n",
    "    result = process_single_period(period, study_area, SCALE)\n",
    "    if result is not None:\n",
    "        processed_images.append(result)\n",
    "        successful_periods.append(period)\n",
    "    \n",
    "    # Progress update every 10 periods\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"\\n--- Completed {i + 1}/{len(periods)} periods ---\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ Successfully processed {len(processed_images)} out of {len(periods)} periods\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create ImageCollection from processed images\n",
    "if processed_images:\n",
    "    time_series_collection = ee.ImageCollection(processed_images)\n",
    "    print(f\"\\n‚úÖ Created time series collection with {time_series_collection.size().getInfo()} images\")\n",
    "    print(f\"   All images contain bands: ['VV', 'VH', 'S2ndvi']\")\n",
    "    print(f\"   NDVI source: Sentinel-2 Level-2A Surface Reflectance (cloud-masked)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No images were successfully processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate NDVI Values (DIAGNOSTIC CHECK)\n",
    "\n",
    "**üîç This cell validates that the S2ndvi band contains actual NDVI values, not backscatter:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç VALIDATING NDVI VALUES (Diagnostic Check)\n",
      "======================================================================\n",
      "\n",
      "Period 1: 2023-11-01 to 2023-11-12\n",
      "  VV range:     [-22.66, 7.69] dB\n",
      "  VH range:     [-29.60, -0.74] dB\n",
      "  S2ndvi range: [-0.3955, 0.8073]\n",
      "  ‚úÖ All bands have CORRECT ranges!\n",
      "\n",
      "Period 32: 2024-11-07 to 2024-11-18\n",
      "  VV range:     [-23.49, 7.17] dB\n",
      "  VH range:     [-31.87, 0.74] dB\n",
      "  S2ndvi range: [-0.5631, 0.8857]\n",
      "  ‚úÖ All bands have CORRECT ranges!\n",
      "\n",
      "Period 62: 2025-11-02 to 2025-11-07\n",
      "  VV range:     [-24.48, 6.50] dB\n",
      "  VH range:     [-33.81, -0.46] dB\n",
      "  S2ndvi range: [-1.0000, 1.0000]\n",
      "  ‚úÖ All bands have CORRECT ranges!\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Validation complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üîç VALIDATING NDVI VALUES (Diagnostic Check)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sample a few periods to check NDVI ranges\n",
    "test_periods = [0, len(successful_periods)//2, len(successful_periods)-1]  # First, middle, last\n",
    "\n",
    "for idx in test_periods:\n",
    "    if idx >= len(processed_images):\n",
    "        continue\n",
    "        \n",
    "    test_image = processed_images[idx]\n",
    "    period_num = successful_periods[idx]['period']\n",
    "    \n",
    "    print(f\"\\nPeriod {period_num}: {successful_periods[idx]['start_str']} to {successful_periods[idx]['end_str']}\")\n",
    "    \n",
    "    try:\n",
    "        # Get statistics for each band\n",
    "        stats = test_image.reduceRegion(\n",
    "            reducer=ee.Reducer.minMax(),\n",
    "            geometry=study_area,\n",
    "            scale=100,  # Use coarser scale for faster computation\n",
    "            maxPixels=1e8,\n",
    "            bestEffort=True\n",
    "        ).getInfo()\n",
    "        \n",
    "        # Check VV band (should be backscatter: -50 to +10 dB)\n",
    "        vv_min = stats.get('VV_min', None)\n",
    "        vv_max = stats.get('VV_max', None)\n",
    "        \n",
    "        # Check VH band (should be backscatter: -50 to +10 dB)\n",
    "        vh_min = stats.get('VH_min', None)\n",
    "        vh_max = stats.get('VH_max', None)\n",
    "        \n",
    "        # Check S2ndvi band (should be NDVI: -1 to 1)\n",
    "        ndvi_min = stats.get('S2ndvi_min', None)\n",
    "        ndvi_max = stats.get('S2ndvi_max', None)\n",
    "        \n",
    "        print(f\"  VV range:     [{vv_min:.2f}, {vv_max:.2f}] dB\")\n",
    "        print(f\"  VH range:     [{vh_min:.2f}, {vh_max:.2f}] dB\")\n",
    "        print(f\"  S2ndvi range: [{ndvi_min:.4f}, {ndvi_max:.4f}]\")\n",
    "        \n",
    "        # Validation\n",
    "        vv_ok = (-60 < vv_min < 10) and (-60 < vv_max < 10)\n",
    "        vh_ok = (-60 < vh_min < 10) and (-60 < vh_max < 10)\n",
    "        ndvi_ok = (-1 <= ndvi_min <= 1) and (-1 <= ndvi_max <= 1)\n",
    "        \n",
    "        if vv_ok and vh_ok and ndvi_ok:\n",
    "            print(f\"  ‚úÖ All bands have CORRECT ranges!\")\n",
    "        else:\n",
    "            if not vv_ok:\n",
    "                print(f\"  ‚ö†Ô∏è VV range unusual (expected -50 to +10 dB)\")\n",
    "            if not vh_ok:\n",
    "                print(f\"  ‚ö†Ô∏è VH range unusual (expected -50 to +10 dB)\")\n",
    "            if not ndvi_ok:\n",
    "                print(f\"  ‚ùå NDVI range INVALID (expected -1 to 1)!\")\n",
    "                print(f\"      This suggests S2ndvi band contains backscatter, not NDVI\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Could not validate (might be no data): {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Validation complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Data to GEE Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üì§ EXPORT CONFIGURATION (FIXED DATA)\n",
      "======================================================================\n",
      "   Asset path: projects/ee-geodeticengineeringundip/assets/FuseTS2\n",
      "   Number of periods: 62\n",
      "   Data version: FIXED_v2 (Level-2A SR, cloud-masked)\n",
      "\n",
      "üöÄ Preparing asset export...\n",
      "\n",
      "üìã Created 62 export tasks\n",
      "\n",
      "üí° To start exports, uncomment the code below:\n",
      "\n",
      "# Start first 10 tasks:\n",
      "# for i, task in enumerate(export_tasks[:10]):\n",
      "#     task.start()\n",
      "#     print(f'Started Period {i+1:02d}')\n",
      "\n",
      "üìä After exports complete, load data with:\n",
      "   var collection = ee.ImageCollection('projects/ee-geodeticengineeringundip/assets/FuseTS2/S1_S2_Nov2023_Oct2025_FIXED_Period_*');\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def export_timeseries_to_asset(collection, geometry, scale, asset_id):\n",
    "    \"\"\"\n",
    "    Export the time series collection to GEE Assets as ImageCollection\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    image_list = collection.toList(collection.size())\n",
    "    \n",
    "    for i in range(len(successful_periods)):\n",
    "        image = ee.Image(image_list.get(i))\n",
    "        period_num = successful_periods[i]['period']\n",
    "        period_info = successful_periods[i]\n",
    "        \n",
    "        # Add comprehensive metadata\n",
    "        image_with_metadata = image.set({\n",
    "            'period': period_num,\n",
    "            'start_date': period_info['start_str'],\n",
    "            'end_date': period_info['end_str'],\n",
    "            'center_date': period_info['center_date'].strftime('%Y-%m-%d'),\n",
    "            'doy_center': period_info['doy_center'],\n",
    "            'year': period_info['year'],\n",
    "            'month': period_info['month'],\n",
    "            'system:time_start': ee.Date(period_info['start_str']).millis(),\n",
    "            'system:time_end': ee.Date(period_info['end_str']).millis(),\n",
    "            'data_version': 'FIXED_v2',\n",
    "            'ndvi_source': 'S2_SR_HARMONIZED',\n",
    "            'cloud_masked': True\n",
    "        })\n",
    "        \n",
    "        # Create asset ID for this period\n",
    "        period_asset_id = f'{asset_id}_Period_{period_num:02d}'\n",
    "        \n",
    "        task = ee.batch.Export.image.toAsset(\n",
    "            image=image_with_metadata,\n",
    "            description=f'AssetFixed_Period_{period_num:02d}',\n",
    "            assetId=period_asset_id,\n",
    "            scale=scale,\n",
    "            region=geometry,\n",
    "            maxPixels=1e13,\n",
    "            crs='EPSG:4326',\n",
    "            pyramidingPolicy={'.default': 'mean'}\n",
    "        )\n",
    "        \n",
    "        tasks.append(task)\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "# Export configuration\n",
    "ASSET_BASE_PATH = 'projects/ee-geodeticengineeringundip/assets/FuseTS2'\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì§ EXPORT CONFIGURATION (FIXED DATA)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   Asset path: {ASSET_BASE_PATH}\")\n",
    "print(f\"   Number of periods: {len(processed_images)}\")\n",
    "print(f\"   Data version: FIXED_v2 (Level-2A SR, cloud-masked)\")\n",
    "\n",
    "if time_series_collection:\n",
    "    print(\"\\nüöÄ Preparing asset export...\")\n",
    "    \n",
    "    asset_id = f'{ASSET_BASE_PATH}/S1_S2_Nov2023_Oct2025_FIXED'\n",
    "    \n",
    "    export_tasks = export_timeseries_to_asset(\n",
    "        time_series_collection,\n",
    "        study_area,\n",
    "        SCALE,\n",
    "        asset_id\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã Created {len(export_tasks)} export tasks\")\n",
    "    print(f\"\\nüí° To start exports, uncomment the code below:\")\n",
    "    print(f\"\\n# Start first 10 tasks:\")\n",
    "    print(f\"# for i, task in enumerate(export_tasks[:10]):\")\n",
    "    print(f\"#     task.start()\")\n",
    "    print(f\"#     print(f'Started Period {{i+1:02d}}')\")\n",
    "    \n",
    "    print(f\"\\nüìä After exports complete, load data with:\")\n",
    "    print(f\"   var collection = ee.ImageCollection('{asset_id}_Period_*');\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No data to export!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Period 01\n",
      "Started Period 02\n",
      "Started Period 03\n",
      "Started Period 04\n",
      "Started Period 05\n",
      "Started Period 06\n",
      "Started Period 07\n",
      "Started Period 08\n",
      "Started Period 09\n",
      "Started Period 10\n"
     ]
    }
   ],
   "source": [
    "# Start first 10 tasks:\n",
    "for i, task in enumerate(export_tasks[:10]):\n",
    "    task.start()\n",
    "    print(f'Started Period {i+1:02d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ‚úÖ FIXES APPLIED IN THIS NOTEBOOK:\n",
    "\n",
    "1. **Level-2A Surface Reflectance**: Uses `COPERNICUS/S2_SR_HARMONIZED` instead of Level-1C TOA\n",
    "   - More accurate (atmospherically corrected)\n",
    "   - Better absolute NDVI values\n",
    "\n",
    "2. **Cloud Masking**: Applied using QA60 band\n",
    "   - Removes cloudy pixels\n",
    "   - Better NDVI quality\n",
    "\n",
    "3. **NDVI Validation**: Clamped to [-1, 1] range\n",
    "   - Prevents out-of-range values\n",
    "   - Catches errors early\n",
    "\n",
    "4. **Band Selection**: Explicitly selects and renames NDVI band\n",
    "   - No ambiguity with VV/VH bands\n",
    "   - Clear band naming: ['VV', 'VH', 'S2ndvi']\n",
    "\n",
    "5. **Diagnostic Checks**: Validates NDVI values before export\n",
    "   - Confirms S2ndvi contains NDVI (-1 to 1)\n",
    "   - Not backscatter (-50 to +10 dB)\n",
    "\n",
    "### Expected NDVI Range After Fix:\n",
    "- **S2ndvi band**: -1.0 to 1.0 ‚úÖ (CORRECT)\n",
    "- **VV band**: -50 to +10 dB (backscatter)\n",
    "- **VH band**: -50 to +10 dB (backscatter)\n",
    "\n",
    "### Next Steps:\n",
    "1. Run validation cell (Cell 6) to confirm NDVI ranges are correct\n",
    "2. Export to GEE Assets (Cell 7)\n",
    "3. Re-run improved DL fusion training with corrected NDVI data\n",
    "4. Expected R¬≤ should improve from -0.8 to 0.55-0.70\n",
    "\n",
    "### Trade-offs:\n",
    "- **Coverage**: May be slightly lower than Level-1C (due to cloud masking)\n",
    "- **Quality**: Much better NDVI quality (atmospherically corrected, cloud-free)\n",
    "- **For S1‚ÜíNDVI fusion**: Quality > Coverage, so this is the right trade-off"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MOGPR H100)",
   "language": "python",
   "name": "mogpr_h100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
