{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Earth Engine Data Preparation for FuseTS\n",
    "\n",
    "This notebook extracts Sentinel-1 and Sentinel-2 data from Google Earth Engine and prepares it for FuseTS MOGPR processing.\n",
    "\n",
    "## Temporal Compositing Strategy\n",
    "- **Total periods**: 31 periods from Nov 2024 - Oct 2025\n",
    "- **Period length**: 12 days each\n",
    "- **Start date**: November 1, 2024\n",
    "- **End date**: October 31, 2025\n",
    "- **Period 1**: Nov 1-12, 2024\n",
    "- **Period 2**: Nov 13-24, 2024  \n",
    "- **Period 3**: Nov 25 - Dec 6, 2024\n",
    "- **... and so on**\n",
    "\n",
    "## Indonesian Agricultural Calendar Coverage\n",
    "This date range perfectly captures:\n",
    "- **First planting season**: Nov 2024 - Mar 2025 (crosses year boundary)\n",
    "- **Second planting season**: Apr - Jun 2025\n",
    "- **Third planting season**: Jul - Sep 2025 (optional)\n",
    "- **Full cycle**: Complete agricultural year\n",
    "\n",
    "## Output Format\n",
    "Data will be exported in FuseTS-compatible xarray format with proper band naming:\n",
    "- S1: `VV`, `VH` bands\n",
    "- S2: `S2ndvi` band\n",
    "- Dimensions: `(time, y, x)` with `t` coordinate name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Additional imports for mask processing\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape, mapping\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Initialize Earth Engine with authentication\n",
    "print(\"üîê Authenticating with Google Earth Engine...\")\n",
    "\n",
    "try:\n",
    "    # First time setup: authenticate\n",
    "    ee.Authenticate()\n",
    "    print(\"‚úÖ Authentication successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Authentication note: {e}\")\n",
    "    print(\"If already authenticated, continuing...\")\n",
    "\n",
    "# Initialize with project\n",
    "try:\n",
    "    ee.Initialize(project='ee-geodeticengineeringundip')\n",
    "    print(\"‚úÖ Earth Engine initialized successfully!\")\n",
    "    print(f\"   Project: ee-geodeticengineeringundip\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing Earth Engine: {e}\")\n",
    "    print(\"Please ensure:\")\n",
    "    print(\"  1. You have run ee.Authenticate() successfully\")\n",
    "    print(\"  2. You have access to project 'ee-geodeticengineeringundip'\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nüì¶ Package versions:\")\n",
    "print(f\"   Earth Engine API: {ee.__version__}\")\n",
    "print(f\"   geemap: {geemap.__version__}\")\n",
    "print(f\"   rasterio: {rasterio.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Study Area and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STUDY AREA SELECTION\n",
    "# ============================================================================\n",
    "\n",
    "# Choose your study area:\n",
    "STUDY_AREA_TYPE = 'demak'  # Options: 'java_island' or 'demak'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìç STUDY AREA CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if STUDY_AREA_TYPE == 'demak':\n",
    "    # ========================================================================\n",
    "    # OPTION 1: KABUPATEN DEMAK (Small area - faster processing)\n",
    "    # ========================================================================\n",
    "    print(\"\\nüéØ Using Kabupaten Demak, Central Java\")\n",
    "    \n",
    "    # Demak administrative boundary (approximate coordinates)\n",
    "    # You can adjust these based on your specific area of interest\n",
    "    demak_bounds = {\n",
    "        'west': 110.35,   # Western boundary\n",
    "        'east': 110.75,   # Eastern boundary  \n",
    "        'south': -7.05,   # Southern boundary\n",
    "        'north': -6.75    # Northern boundary\n",
    "    }\n",
    "    \n",
    "    # Create rectangle geometry for Demak\n",
    "    study_area = ee.Geometry.Rectangle([\n",
    "        demak_bounds['west'], \n",
    "        demak_bounds['south'],\n",
    "        demak_bounds['east'], \n",
    "        demak_bounds['north']\n",
    "    ])\n",
    "    \n",
    "    # Alternative: Use GEE administrative boundaries (more accurate)\n",
    "    # Uncomment these lines to use official boundaries:\n",
    "    # admin_boundaries = ee.FeatureCollection(\"FAO/GAUL/2015/level2\")\n",
    "    # demak = admin_boundaries.filter(ee.Filter.eq('ADM2_NAME', 'Demak'))\n",
    "    # study_area = demak.geometry()\n",
    "    \n",
    "    print(f\"   Type: Administrative boundary (regency/kabupaten)\")\n",
    "    print(f\"   Location: Central Java Province\")\n",
    "    print(f\"   Approximate area: ~900 km¬≤\")\n",
    "    print(f\"   Bounds: {demak_bounds}\")\n",
    "    print(f\"   ‚úÖ Much smaller than Java Island ‚Üí faster export!\")\n",
    "    \n",
    "elif STUDY_AREA_TYPE == 'java_island':\n",
    "    # ========================================================================\n",
    "    # OPTION 2: FULL JAVA ISLAND (Large area - requires more storage)\n",
    "    # ========================================================================\n",
    "    print(\"\\nüèùÔ∏è  Using Full Java Island\")\n",
    "    \n",
    "    import rasterio\n",
    "    from rasterio.features import shapes\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import shape, mapping\n",
    "    \n",
    "    # Path to Java Island mask\n",
    "    MASK_FILE = 'java_island_mask.tif'\n",
    "    \n",
    "    print(f\"   Loading Java Island mask from: {MASK_FILE}\")\n",
    "    \n",
    "    # Read the mask file and extract geometry\n",
    "    with rasterio.open(MASK_FILE) as src:\n",
    "        # Read the mask (assuming mask values > 0 indicate valid areas)\n",
    "        mask_data = src.read(1)\n",
    "        mask_transform = src.transform\n",
    "        mask_crs = src.crs\n",
    "        \n",
    "        # Get bounds\n",
    "        bounds = src.bounds\n",
    "        print(f\"   Mask bounds: {bounds}\")\n",
    "        print(f\"   Mask CRS: {mask_crs}\")\n",
    "        print(f\"   Mask shape: {mask_data.shape}\")\n",
    "        \n",
    "        # Extract geometry from mask (vectorize the raster mask)\n",
    "        mask_geoms = []\n",
    "        for geom, val in shapes(mask_data, mask=mask_data > 0, transform=mask_transform):\n",
    "            mask_geoms.append(shape(geom))\n",
    "    \n",
    "    # Create a unified geometry for Java Island\n",
    "    if len(mask_geoms) > 0:\n",
    "        from shapely.ops import unary_union\n",
    "        java_geometry = unary_union(mask_geoms)\n",
    "        \n",
    "        # Add 5 km buffer to the Java Island geometry\n",
    "        BUFFER_DISTANCE_KM = 5\n",
    "        BUFFER_DISTANCE_DEGREES = BUFFER_DISTANCE_KM / 111.0  # Approximate conversion (1 degree ‚âà 111 km)\n",
    "        \n",
    "        print(f\"   Applying {BUFFER_DISTANCE_KM} km buffer to Java Island mask...\")\n",
    "        java_geometry_buffered = java_geometry.buffer(BUFFER_DISTANCE_DEGREES)\n",
    "        \n",
    "        # Convert to GeoJSON format for Earth Engine\n",
    "        java_geojson = mapping(java_geometry_buffered)\n",
    "        \n",
    "        # Upload to Earth Engine\n",
    "        study_area = ee.Geometry(java_geojson)\n",
    "        \n",
    "        print(f\"   ‚úÖ Java Island mask loaded successfully!\")\n",
    "        print(f\"   Number of geometries merged: {len(mask_geoms)}\")\n",
    "        print(f\"   Buffer applied: {BUFFER_DISTANCE_KM} km\")\n",
    "        print(f\"   Approximate area: ~150,000 km¬≤\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No valid mask areas found, falling back to bounding box\")\n",
    "        study_area = ee.Geometry.Rectangle([bounds.left, bounds.bottom, bounds.right, bounds.top])\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Invalid STUDY_AREA_TYPE: {STUDY_AREA_TYPE}. Use 'demak' or 'java_island'\")\n",
    "\n",
    "# Processing parameters\n",
    "START_DATE = '2024-11-01'  # November 1, 2024\n",
    "END_DATE = '2025-10-31'    # October 31, 2025\n",
    "SCALE = 50  # meters per pixel (50m resolution for both S1 and S2)\n",
    "CRS = 'EPSG:4326'  # WGS84 coordinate system\n",
    "MAX_CLOUD_COVER = 20  # Maximum cloud cover percentage for S2\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = 'gee_fusets_data'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Display final configuration\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìã FINAL CONFIGURATION\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   Study Area: {STUDY_AREA_TYPE.upper()}\")\n",
    "print(f\"   Bounds: {study_area.bounds().getInfo()}\")\n",
    "print(f\"   Area size: {study_area.area().getInfo() / 1e6:.1f} km¬≤\")\n",
    "print(f\"   Processing period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"   Temporal resolution: 12-day composites (31 periods)\")\n",
    "print(f\"   Spatial resolution: {SCALE}m\")\n",
    "print(f\"   Coordinate system: {CRS}\")\n",
    "print(f\"   Max cloud cover: {MAX_CLOUD_COVER}%\")\n",
    "print(f\"   Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Estimate data size\n",
    "area_km2 = study_area.area().getInfo() / 1e6\n",
    "pixels_per_period = (area_km2 * 1e6) / (SCALE * SCALE)  # Total pixels\n",
    "bands = 3  # VV, VH, S2ndvi\n",
    "bytes_per_pixel = 4  # Float32\n",
    "total_size_gb = (pixels_per_period * bands * bytes_per_pixel * 31) / 1e9\n",
    "\n",
    "print(f\"\\nüíæ Estimated data size:\")\n",
    "print(f\"   Per period: ~{total_size_gb/31:.2f} GB\")\n",
    "print(f\"   Total (31 periods): ~{total_size_gb:.1f} GB\")\n",
    "\n",
    "if total_size_gb > 250:\n",
    "    print(f\"\\n   ‚ö†Ô∏è  WARNING: Exceeds GEE Asset quota (250GB)\")\n",
    "    print(f\"   ‚Üí Use Google Drive export instead\")\n",
    "elif total_size_gb > 100:\n",
    "    print(f\"\\n   ‚ö° Large dataset - GEE Assets recommended\")\n",
    "else:\n",
    "    print(f\"\\n   ‚úÖ Manageable size - Google Drive or Assets both work\")\n",
    "\n",
    "print(f\"{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate 12-Day Composite Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_12day_periods(start_date_str, end_date_str):\n",
    "    \"\"\"\n",
    "    Generate 31 periods of 12 days each from Nov 1, 2024 to Oct 31, 2025\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    start_date_str : str\n",
    "        Start date in 'YYYY-MM-DD' format (e.g., '2024-11-01')\n",
    "    end_date_str : str\n",
    "        End date in 'YYYY-MM-DD' format (e.g., '2025-10-31')\n",
    "    \"\"\"\n",
    "    start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "    \n",
    "    periods = []\n",
    "    \n",
    "    for period_num in range(31):\n",
    "        period_start = start_date + timedelta(days=period_num * 12)\n",
    "        period_end = period_start + timedelta(days=11)  # 12 days inclusive\n",
    "        \n",
    "        # Ensure we don't go beyond the end date\n",
    "        if period_end > end_date:\n",
    "            period_end = end_date\n",
    "            \n",
    "        periods.append({\n",
    "            'period': period_num + 1,\n",
    "            'start_date': period_start,\n",
    "            'end_date': period_end,\n",
    "            'start_str': period_start.strftime('%Y-%m-%d'),\n",
    "            'end_str': period_end.strftime('%Y-%m-%d'),\n",
    "            'center_date': period_start + timedelta(days=6),  # Middle of period\n",
    "            'doy_center': (period_start + timedelta(days=6)).timetuple().tm_yday,\n",
    "            'year': period_start.year,\n",
    "            'month': period_start.month\n",
    "        })\n",
    "        \n",
    "        if period_end >= end_date:\n",
    "            break\n",
    "            \n",
    "    return periods\n",
    "\n",
    "# Generate periods from Nov 2024 to Oct 2025\n",
    "periods = generate_12day_periods(START_DATE, END_DATE)\n",
    "\n",
    "print(f\"Generated {len(periods)} periods from {START_DATE} to {END_DATE}:\")\n",
    "print(\"\\nFirst 5 periods:\")\n",
    "for i, period in enumerate(periods[:5]):\n",
    "    print(f\"Period {period['period']:2d}: {period['start_str']} to {period['end_str']} (center: DOY {period['doy_center']:3d}, {period['year']})\")\n",
    "\n",
    "print(\"\\nPeriods crossing year boundary (Dec 2024 -> Jan 2025):\")\n",
    "year_boundary_periods = [p for p in periods if p['start_date'].year != p['end_date'].year]\n",
    "for period in year_boundary_periods:\n",
    "    print(f\"Period {period['period']:2d}: {period['start_str']} to {period['end_str']} ‚Üê CROSSES YEAR BOUNDARY\")\n",
    "\n",
    "print(\"\\nLast 5 periods:\")\n",
    "for i, period in enumerate(periods[-5:]):\n",
    "    print(f\"Period {period['period']:2d}: {period['start_str']} to {period['end_str']} (center: DOY {period['doy_center']:3d}, {period['year']})\")\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "periods_df = pd.DataFrame(periods)\n",
    "print(f\"\\nTotal temporal coverage: {periods[0]['start_str']} to {periods[-1]['end_str']}\")\n",
    "print(f\"Covers Indonesian agricultural seasons:\")\n",
    "print(f\"  ‚Ä¢ Season 1 (Nov-Mar): Periods 1-11 (Nov 2024 - Mar 2025)\")\n",
    "print(f\"  ‚Ä¢ Season 2 (Apr-Jun): Periods 12-18 (Apr - Jun 2025)\")\n",
    "print(f\"  ‚Ä¢ Season 3 (Jul-Sep): Periods 19-25 (Jul - Sep 2025)\")\n",
    "print(f\"  ‚Ä¢ Full coverage: Through Period 31 (Oct 2025)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentinel1_data(geometry, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Load Sentinel-1 GRD data for a specific time period\n",
    "    \"\"\"\n",
    "    s1_collection = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "                    .filterBounds(geometry)\n",
    "                    .filterDate(start_date, end_date)\n",
    "                    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "                    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "                    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
    "                    .select(['VV', 'VH']))\n",
    "    \n",
    "    return s1_collection\n",
    "\n",
    "def load_sentinel2_data(geometry, start_date, end_date, max_cloud_cover=20):\n",
    "    \"\"\"\n",
    "    Load Sentinel-2 data and calculate NDVI for a specific time period\n",
    "    \"\"\"\n",
    "    def calculate_ndvi(image):\n",
    "        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        return image.addBands(ndvi)\n",
    "    \n",
    "    def mask_clouds(image):\n",
    "        # Use SCL band for cloud masking\n",
    "        scl = image.select('SCL')\n",
    "        # Keep vegetation, soil, water, snow classes (4,5,6,11)\n",
    "        good_pixels = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(11))\n",
    "        return image.updateMask(good_pixels)\n",
    "    \n",
    "    s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                    .filterBounds(geometry)\n",
    "                    .filterDate(start_date, end_date)\n",
    "                    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "                    .map(mask_clouds)\n",
    "                    .map(calculate_ndvi)\n",
    "                    .select(['NDVI']))\n",
    "    \n",
    "    return s2_collection\n",
    "\n",
    "def create_composite(collection, method='median'):\n",
    "    \"\"\"\n",
    "    Create a composite from an image collection\n",
    "    \"\"\"\n",
    "    if method == 'median':\n",
    "        return collection.median()\n",
    "    elif method == 'mean':\n",
    "        return collection.mean()\n",
    "    elif method == 'max':\n",
    "        return collection.max()\n",
    "    else:\n",
    "        return collection.median()\n",
    "\n",
    "print(\"Data loading functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Data for All Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_period(period_info, geometry, scale=10):\n",
    "    \"\"\"\n",
    "    Process S1 and S2 data for a single 12-day period\n",
    "    \"\"\"\n",
    "    start_date = period_info['start_str']\n",
    "    end_date = period_info['end_str']\n",
    "    period_num = period_info['period']\n",
    "    \n",
    "    print(f\"Processing Period {period_num}: {start_date} to {end_date}\")\n",
    "    \n",
    "    try:\n",
    "        # Load Sentinel-1 data\n",
    "        s1_collection = load_sentinel1_data(geometry, start_date, end_date)\n",
    "        s1_count = s1_collection.size().getInfo()\n",
    "        \n",
    "        # Load Sentinel-2 data\n",
    "        s2_collection = load_sentinel2_data(geometry, start_date, end_date, MAX_CLOUD_COVER)\n",
    "        s2_count = s2_collection.size().getInfo()\n",
    "        \n",
    "        print(f\"  Found {s1_count} S1 images, {s2_count} S2 images\")\n",
    "        \n",
    "        # Create composites\n",
    "        if s1_count > 0:\n",
    "            s1_composite = create_composite(s1_collection, 'median')\n",
    "        else:\n",
    "            # Create empty image with correct bands\n",
    "            s1_composite = ee.Image.constant([0, 0]).rename(['VV', 'VH']).updateMask(ee.Image.constant(0))\n",
    "            \n",
    "        if s2_count > 0:\n",
    "            s2_composite = create_composite(s2_collection, 'median')\n",
    "        else:\n",
    "            # Create empty NDVI image\n",
    "            s2_composite = ee.Image.constant(0).rename('NDVI').updateMask(ee.Image.constant(0))\n",
    "        \n",
    "        # Combine S1 and S2 data\n",
    "        combined_image = s1_composite.addBands(s2_composite.rename('S2ndvi'))\n",
    "        \n",
    "        # Add metadata\n",
    "        combined_image = combined_image.set({\n",
    "            'period': period_num,\n",
    "            'start_date': start_date,\n",
    "            'end_date': end_date,\n",
    "            'center_date': period_info['center_date'].strftime('%Y-%m-%d'),\n",
    "            'doy_center': period_info['doy_center'],\n",
    "            's1_count': s1_count,\n",
    "            's2_count': s2_count\n",
    "        })\n",
    "        \n",
    "        return combined_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing period {period_num}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process all periods\n",
    "print(\"Starting data processing for all periods...\\n\")\n",
    "\n",
    "processed_images = []\n",
    "successful_periods = []\n",
    "\n",
    "for i, period in enumerate(periods):\n",
    "    result = process_single_period(period, study_area, SCALE)\n",
    "    if result is not None:\n",
    "        processed_images.append(result)\n",
    "        successful_periods.append(period)\n",
    "    \n",
    "    # Progress update every 5 periods\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"Completed {i + 1}/{len(periods)} periods\\n\")\n",
    "\n",
    "print(f\"Successfully processed {len(processed_images)} out of {len(periods)} periods\")\n",
    "\n",
    "# Create ImageCollection from processed images\n",
    "if processed_images:\n",
    "    time_series_collection = ee.ImageCollection(processed_images)\n",
    "    print(f\"Created time series collection with {time_series_collection.size().getInfo()} images\")\n",
    "else:\n",
    "    print(\"No images were successfully processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Data from GEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b. Preview 12-Day Composites\n",
    "\n",
    "Before exporting all 31 periods, let's preview a few composites to verify the data quality and spatial coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREVIEW COMPOSITES BEFORE EXPORT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç PREVIEW: 12-Day Composites Quality Check\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select a few sample periods to preview\n",
    "sample_periods = [0, 10, 20, 30]  # Period 1, 11, 21, 31 (spread across the year)\n",
    "\n",
    "print(f\"\\nüìä Previewing {len(sample_periods)} sample periods:\")\n",
    "for idx in sample_periods:\n",
    "    if idx < len(successful_periods):\n",
    "        p = successful_periods[idx]\n",
    "        print(f\"   Period {p['period']:2d}: {p['start_str']} to {p['end_str']}\")\n",
    "\n",
    "# Create visualization map\n",
    "print(\"\\nüó∫Ô∏è  Creating interactive map...\")\n",
    "Map = geemap.Map(center=[-7.2, 110.5], zoom=7)\n",
    "\n",
    "# Add Java Island boundary for reference\n",
    "Map.addLayer(study_area, {'color': 'red'}, 'Study Area (Java Island + 5km buffer)', opacity=0.3)\n",
    "\n",
    "# Visualization parameters for different bands\n",
    "vis_params_vv = {\n",
    "    'min': -25,\n",
    "    'max': 0,\n",
    "    'palette': ['blue', 'yellow', 'red']\n",
    "}\n",
    "\n",
    "vis_params_vh = {\n",
    "    'min': -30,\n",
    "    'max': -5,\n",
    "    'palette': ['blue', 'green', 'yellow']\n",
    "}\n",
    "\n",
    "vis_params_ndvi = {\n",
    "    'min': 0,\n",
    "    'max': 1,\n",
    "    'palette': ['brown', 'yellow', 'green', 'darkgreen']\n",
    "}\n",
    "\n",
    "# Add sample periods to map\n",
    "for idx in sample_periods:\n",
    "    if idx < len(processed_images):\n",
    "        image = processed_images[idx]\n",
    "        period_info = successful_periods[idx]\n",
    "        period_num = period_info['period']\n",
    "        \n",
    "        # Add each band as a separate layer\n",
    "        Map.addLayer(\n",
    "            image.select('VV'), \n",
    "            vis_params_vv, \n",
    "            f'Period {period_num:02d} - S1 VV', \n",
    "            shown=False\n",
    "        )\n",
    "        \n",
    "        Map.addLayer(\n",
    "            image.select('VH'), \n",
    "            vis_params_vh, \n",
    "            f'Period {period_num:02d} - S1 VH', \n",
    "            shown=False\n",
    "        )\n",
    "        \n",
    "        Map.addLayer(\n",
    "            image.select('S2ndvi'), \n",
    "            vis_params_ndvi, \n",
    "            f'Period {period_num:02d} - S2 NDVI', \n",
    "            shown=(idx == 0)  # Show only first period by default\n",
    "        )\n",
    "        \n",
    "        # RGB composite (false color)\n",
    "        rgb_vis = {\n",
    "            'min': [0, -25, -30],\n",
    "            'max': [1, 0, -5],\n",
    "            'bands': ['S2ndvi', 'VV', 'VH']\n",
    "        }\n",
    "        Map.addLayer(\n",
    "            image, \n",
    "            rgb_vis, \n",
    "            f'Period {period_num:02d} - RGB (NDVI/VV/VH)', \n",
    "            shown=False\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ Map created! Toggle layers in the map to compare periods and bands\")\n",
    "print(\"   ‚Ä¢ Red outline: Study area boundary\")\n",
    "print(\"   ‚Ä¢ VV: Sentinel-1 VV polarization (blue=low, red=high backscatter)\")\n",
    "print(\"   ‚Ä¢ VH: Sentinel-1 VH polarization (blue=low, yellow=high backscatter)\")\n",
    "print(\"   ‚Ä¢ NDVI: Vegetation index (brown=no veg, green=dense vegetation)\")\n",
    "print(\"   ‚Ä¢ RGB: False color composite (Red=NDVI, Green=VV, Blue=VH)\")\n",
    "\n",
    "# Display the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PIXEL-LEVEL DATA QUALITY CHECK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà PIXEL DATA QUALITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define sample points across Java Island\n",
    "sample_points = [\n",
    "    {'name': 'Western Banten', 'lon': 106.0, 'lat': -6.5},\n",
    "    {'name': 'West Java (Bandung)', 'lon': 107.6, 'lat': -6.9},\n",
    "    {'name': 'Central Java (Semarang)', 'lon': 110.4, 'lat': -7.0},\n",
    "    {'name': 'Central Java Coast', 'lon': 109.0, 'lat': -6.8},\n",
    "    {'name': 'East Java (Surabaya)', 'lon': 112.7, 'lat': -7.3},\n",
    "    {'name': 'Eastern Java', 'lon': 114.2, 'lat': -8.0}\n",
    "]\n",
    "\n",
    "print(f\"\\nüéØ Sampling {len(sample_points)} locations across Java Island:\")\n",
    "for pt in sample_points:\n",
    "    print(f\"   ‚Ä¢ {pt['name']:25s} ({pt['lon']:6.2f}¬∞E, {pt['lat']:5.2f}¬∞N)\")\n",
    "\n",
    "# Sample first period to check for data availability\n",
    "if len(processed_images) > 0:\n",
    "    first_image = processed_images[0]\n",
    "    \n",
    "    print(f\"\\nüìä Checking Period 1 data at sample locations...\")\n",
    "    print(f\"{'Location':<25s} {'VV':>8s} {'VH':>8s} {'NDVI':>8s} {'Status':>12s}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for pt in sample_points:\n",
    "        point = ee.Geometry.Point([pt['lon'], pt['lat']])\n",
    "        \n",
    "        # Sample the image at this point\n",
    "        try:\n",
    "            sample = first_image.sample(point, scale=SCALE).first().getInfo()\n",
    "            \n",
    "            if sample and 'properties' in sample:\n",
    "                props = sample['properties']\n",
    "                vv = props.get('VV', None)\n",
    "                vh = props.get('VH', None)\n",
    "                ndvi = props.get('S2ndvi', None)\n",
    "                \n",
    "                # Check if data exists\n",
    "                if vv is not None and vh is not None and ndvi is not None:\n",
    "                    status = \"‚úÖ HAS DATA\"\n",
    "                    vv_str = f\"{vv:8.2f}\"\n",
    "                    vh_str = f\"{vh:8.2f}\"\n",
    "                    ndvi_str = f\"{ndvi:8.3f}\"\n",
    "                else:\n",
    "                    status = \"‚ùå NO DATA\"\n",
    "                    vv_str = \"None\" if vv is None else f\"{vv:8.2f}\"\n",
    "                    vh_str = \"None\" if vh is None else f\"{vh:8.2f}\"\n",
    "                    ndvi_str = \"None\" if ndvi is None else f\"{ndvi:8.3f}\"\n",
    "                \n",
    "                print(f\"{pt['name']:<25s} {vv_str:>8s} {vh_str:>8s} {ndvi_str:>8s} {status:>12s}\")\n",
    "            else:\n",
    "                print(f\"{pt['name']:<25s} {'None':>8s} {'None':>8s} {'None':>8s} {'‚ùå NO DATA':>12s}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"{pt['name']:<25s} {'Error':>8s} {'Error':>8s} {'Error':>8s} {'‚ùå ERROR':>12s}\")\n",
    "    \n",
    "    print(\"\\nüí° Interpretation:\")\n",
    "    print(\"   ‚Ä¢ VV/VH values between -30 to 0 dB are normal for Sentinel-1\")\n",
    "    print(\"   ‚Ä¢ NDVI values between 0 to 1 are normal (0=no vegetation, 1=dense)\")\n",
    "    print(\"   ‚Ä¢ 'None' values indicate missing data (possible mask issue)\")\n",
    "    \n",
    "    # Check if Java Island mask was properly applied\n",
    "    print(\"\\n‚ö†Ô∏è  IMPORTANT:\")\n",
    "    print(\"   If you see 'NO DATA' for most locations, the Java Island mask\")\n",
    "    print(\"   might not be properly applied during export. This is the issue\")\n",
    "    print(\"   we identified earlier. Make sure to apply the mask fix before export!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No processed images available for quality check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TIME SERIES PROFILE AT SAMPLE LOCATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìâ TIME SERIES PROFILE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Pick one location for detailed time series analysis\n",
    "test_location = {'name': 'Central Java (Agricultural Area)', 'lon': 110.4, 'lat': -7.0}\n",
    "test_point = ee.Geometry.Point([test_location['lon'], test_location['lat']])\n",
    "\n",
    "print(f\"\\nüìç Extracting full time series at: {test_location['name']}\")\n",
    "print(f\"   Coordinates: {test_location['lon']:.2f}¬∞E, {test_location['lat']:.2f}¬∞N\")\n",
    "\n",
    "# Extract values for all periods\n",
    "time_series_data = {\n",
    "    'period': [],\n",
    "    'date': [],\n",
    "    'VV': [],\n",
    "    'VH': [],\n",
    "    'NDVI': []\n",
    "}\n",
    "\n",
    "print(\"\\n‚è≥ Extracting data from all periods...\")\n",
    "for i, (image, period_info) in enumerate(zip(processed_images, successful_periods)):\n",
    "    try:\n",
    "        sample = image.sample(test_point, scale=SCALE).first().getInfo()\n",
    "        \n",
    "        if sample and 'properties' in sample:\n",
    "            props = sample['properties']\n",
    "            time_series_data['period'].append(period_info['period'])\n",
    "            time_series_data['date'].append(period_info['center_date'])\n",
    "            time_series_data['VV'].append(props.get('VV', None))\n",
    "            time_series_data['VH'].append(props.get('VH', None))\n",
    "            time_series_data['NDVI'].append(props.get('S2ndvi', None))\n",
    "        else:\n",
    "            time_series_data['period'].append(period_info['period'])\n",
    "            time_series_data['date'].append(period_info['center_date'])\n",
    "            time_series_data['VV'].append(None)\n",
    "            time_series_data['VH'].append(None)\n",
    "            time_series_data['NDVI'].append(None)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   Error at period {period_info['period']}: {e}\")\n",
    "\n",
    "# Create time series plot\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot VV\n",
    "ax = axes[0]\n",
    "dates = time_series_data['date']\n",
    "vv_vals = [v if v is not None else np.nan for v in time_series_data['VV']]\n",
    "ax.plot(dates, vv_vals, 'o-', color='blue', linewidth=2, markersize=6)\n",
    "ax.set_ylabel('VV Backscatter (dB)', fontsize=11)\n",
    "ax.set_title(f'Sentinel-1/2 Time Series at {test_location[\"name\"]}\\n12-Day Composites (Nov 2024 - Oct 2025)', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot VH\n",
    "ax = axes[1]\n",
    "vh_vals = [v if v is not None else np.nan for v in time_series_data['VH']]\n",
    "ax.plot(dates, vh_vals, 'o-', color='green', linewidth=2, markersize=6)\n",
    "ax.set_ylabel('VH Backscatter (dB)', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot NDVI\n",
    "ax = axes[2]\n",
    "ndvi_vals = [v if v is not None else np.nan for v in time_series_data['NDVI']]\n",
    "ax.plot(dates, ndvi_vals, 'o-', color='darkgreen', linewidth=2, markersize=6)\n",
    "ax.set_ylabel('NDVI', fontsize=11)\n",
    "ax.set_xlabel('Date', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Moderate vegetation')\n",
    "ax.legend()\n",
    "\n",
    "# Highlight agricultural seasons\n",
    "from matplotlib.dates import DateFormatter, MonthLocator\n",
    "for ax in axes:\n",
    "    ax.xaxis.set_major_locator(MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "    \n",
    "    # Season 1: Nov-Mar\n",
    "    ax.axvspan(datetime(2024, 11, 1), datetime(2025, 3, 31), alpha=0.1, color='green', label='Season 1')\n",
    "    # Season 2: Apr-Jun\n",
    "    ax.axvspan(datetime(2025, 4, 1), datetime(2025, 6, 30), alpha=0.1, color='blue', label='Season 2')\n",
    "    # Season 3: Jul-Sep\n",
    "    ax.axvspan(datetime(2025, 7, 1), datetime(2025, 9, 30), alpha=0.1, color='orange', label='Season 3')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'time_series_preview.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä Time Series Summary:\")\n",
    "print(f\"   Valid VV points: {sum(1 for v in vv_vals if not np.isnan(v))}/{len(vv_vals)}\")\n",
    "print(f\"   Valid VH points: {sum(1 for v in vh_vals if not np.isnan(v))}/{len(vh_vals)}\")\n",
    "print(f\"   Valid NDVI points: {sum(1 for v in ndvi_vals if not np.isnan(v))}/{len(ndvi_vals)}\")\n",
    "\n",
    "vv_valid = [v for v in vv_vals if not np.isnan(v)]\n",
    "vh_valid = [v for v in vh_vals if not np.isnan(v)]\n",
    "ndvi_valid = [v for v in ndvi_vals if not np.isnan(v)]\n",
    "\n",
    "if len(vv_valid) > 0:\n",
    "    print(f\"\\n   VV range: {min(vv_valid):.2f} to {max(vv_valid):.2f} dB\")\n",
    "if len(vh_valid) > 0:\n",
    "    print(f\"   VH range: {min(vh_valid):.2f} to {max(vh_valid):.2f} dB\")\n",
    "if len(ndvi_valid) > 0:\n",
    "    print(f\"   NDVI range: {min(ndvi_valid):.3f} to {max(ndvi_valid):.3f}\")\n",
    "\n",
    "print(f\"\\nüíæ Time series plot saved to: {os.path.join(OUTPUT_DIR, 'time_series_preview.png')}\")\n",
    "\n",
    "print(\"\\n‚úÖ PREVIEW COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° Next Steps:\")\n",
    "print(\"   1. Review the interactive map above\")\n",
    "print(\"   2. Check the time series plot for data continuity\")\n",
    "print(\"   3. Verify pixel values are reasonable\")\n",
    "print(\"   4. If everything looks good, proceed to Section 6 (Export)\")\n",
    "print(\"   5. If you see missing data, check the export function for mask application\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c. Coverage Analysis - Check if 12 Days is Enough\n",
    "\n",
    "**IMPORTANT**: Sentinel-1 has a 12-day repeat cycle, but Sentinel-2 has a 5-day repeat cycle (with 2 satellites). However, cloud cover can significantly reduce effective coverage. Let's check if 12-day composites provide full spatial coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SPATIAL COVERAGE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üåç SPATIAL COVERAGE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Analyzing coverage for first few periods...\")\n",
    "print(\"   This checks what percentage of Java Island has valid data\\n\")\n",
    "\n",
    "# Analyze first 3 periods\n",
    "coverage_results = []\n",
    "\n",
    "for idx in range(min(3, len(processed_images))):\n",
    "    image = processed_images[idx]\n",
    "    period_info = successful_periods[idx]\n",
    "    period_num = period_info['period']\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Period {period_num}: {period_info['start_str']} to {period_info['end_str']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Count valid pixels for each band\n",
    "    for band_name in ['VV', 'VH', 'S2ndvi']:\n",
    "        band = image.select(band_name)\n",
    "        \n",
    "        # Create a binary mask (1 = has data, 0 = no data)\n",
    "        valid_mask = band.mask()\n",
    "        \n",
    "        # Calculate statistics over the study area\n",
    "        stats = valid_mask.reduceRegion(\n",
    "            reducer=ee.Reducer.sum().combine(\n",
    "                reducer2=ee.Reducer.count(),\n",
    "                sharedInputs=True\n",
    "            ),\n",
    "            geometry=study_area,\n",
    "            scale=SCALE,\n",
    "            maxPixels=1e10\n",
    "        ).getInfo()\n",
    "        \n",
    "        valid_pixels = stats.get(f'{band_name}_sum', 0)\n",
    "        total_pixels = stats.get(f'{band_name}_count', 1)\n",
    "        coverage_pct = (valid_pixels / total_pixels * 100) if total_pixels > 0 else 0\n",
    "        \n",
    "        print(f\"   {band_name:8s}: {coverage_pct:5.1f}% coverage ({int(valid_pixels):,} / {int(total_pixels):,} pixels)\")\n",
    "        \n",
    "        coverage_results.append({\n",
    "            'period': period_num,\n",
    "            'band': band_name,\n",
    "            'coverage_pct': coverage_pct,\n",
    "            'valid_pixels': valid_pixels,\n",
    "            'total_pixels': total_pixels\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìà COVERAGE SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Group by band\n",
    "for band_name in ['VV', 'VH', 'S2ndvi']:\n",
    "    band_coverage = [r for r in coverage_results if r['band'] == band_name]\n",
    "    avg_coverage = np.mean([r['coverage_pct'] for r in band_coverage])\n",
    "    min_coverage = np.min([r['coverage_pct'] for r in band_coverage])\n",
    "    max_coverage = np.max([r['coverage_pct'] for r in band_coverage])\n",
    "    \n",
    "    print(f\"\\n{band_name:8s}:\")\n",
    "    print(f\"   Average coverage: {avg_coverage:5.1f}%\")\n",
    "    print(f\"   Range: {min_coverage:5.1f}% - {max_coverage:5.1f}%\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üí° INTERPRETATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "s2_coverage = [r['coverage_pct'] for r in coverage_results if r['band'] == 'S2ndvi']\n",
    "s1_coverage = [r['coverage_pct'] for r in coverage_results if r['band'] in ['VV', 'VH']]\n",
    "\n",
    "avg_s2 = np.mean(s2_coverage) if s2_coverage else 0\n",
    "avg_s1 = np.mean(s1_coverage) if s1_coverage else 0\n",
    "\n",
    "print(f\"\\nSentinel-1 (VV/VH) average: {avg_s1:.1f}%\")\n",
    "print(f\"Sentinel-2 (NDVI) average:  {avg_s2:.1f}%\")\n",
    "\n",
    "if avg_s2 < 80:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: S2 coverage is low ({avg_s2:.1f}%)\")\n",
    "    print(\"   Possible reasons:\")\n",
    "    print(\"   ‚Ä¢ 12 days too short for cloud-free S2 coverage\")\n",
    "    print(\"   ‚Ä¢ High cloud cover in tropical Indonesia\")\n",
    "    print(\"   ‚Ä¢ Rainy season (Nov-Mar)\")\n",
    "    print(\"\\nüí° RECOMMENDATIONS:\")\n",
    "    print(\"   1. Increase composite period to 16-30 days for better S2 coverage\")\n",
    "    print(\"   2. Use longer periods during rainy season (Nov-Mar)\")\n",
    "    print(\"   3. Rely more on S1 data (radar, cloud-penetrating)\")\n",
    "    print(\"   4. Adjust MAX_CLOUD_COVER threshold (currently 20%)\")\n",
    "elif avg_s2 < 95:\n",
    "    print(f\"\\n‚ö° S2 coverage is moderate ({avg_s2:.1f}%)\")\n",
    "    print(\"   ‚Ä¢ Should work for MOGPR fusion (fills gaps)\")\n",
    "    print(\"   ‚Ä¢ Consider 16-day periods for more consistent coverage\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ S2 coverage is excellent ({avg_s2:.1f}%)\")\n",
    "    print(\"   ‚Ä¢ 12-day periods work well for this time period\")\n",
    "\n",
    "if avg_s1 < 90:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: S1 coverage is low ({avg_s1:.1f}%)\")\n",
    "    print(\"   This is unusual for Sentinel-1 (radar, all-weather)\")\n",
    "    print(\"   ‚Ä¢ Check if data availability issue\")\n",
    "    print(\"   ‚Ä¢ Verify study area geometry\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ S1 coverage is good ({avg_s1:.1f}%)\")\n",
    "    print(\"   ‚Ä¢ Sentinel-1 provides reliable all-weather coverage\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5d. ALTERNATIVE: Test Different Composite Periods\n",
    "\n",
    "If 12-day coverage is insufficient, let's test what period length gives ~95%+ coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TEST DIFFERENT COMPOSITE PERIOD LENGTHS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üß™ TESTING DIFFERENT COMPOSITE PERIOD LENGTHS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test different period lengths\n",
    "test_periods = [12, 16, 20, 24, 30]  # days\n",
    "\n",
    "print(\"\\nüìä Testing coverage for different composite periods...\")\n",
    "print(\"   (Testing on first period: Nov 1-X, 2024)\\n\")\n",
    "\n",
    "coverage_by_period = {}\n",
    "\n",
    "for days in test_periods:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing {days}-day composite: Nov 1 - Nov {days}, 2024\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    test_start = '2024-11-01'\n",
    "    test_end = (datetime(2024, 11, 1) + timedelta(days=days-1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Load data for this period\n",
    "    s1_test = load_sentinel1_data(study_area, test_start, test_end)\n",
    "    s2_test = load_sentinel2_data(study_area, test_start, test_end, MAX_CLOUD_COVER)\n",
    "    \n",
    "    s1_count = s1_test.size().getInfo()\n",
    "    s2_count = s2_test.size().getInfo()\n",
    "    \n",
    "    print(f\"   S1 images found: {s1_count}\")\n",
    "    print(f\"   S2 images found: {s2_count}\")\n",
    "    \n",
    "    if s1_count > 0:\n",
    "        s1_composite = create_composite(s1_test, 'median')\n",
    "    else:\n",
    "        s1_composite = ee.Image.constant([0, 0]).rename(['VV', 'VH']).updateMask(ee.Image.constant(0))\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        s2_composite = create_composite(s2_test, 'median')\n",
    "    else:\n",
    "        s2_composite = ee.Image.constant(0).rename('NDVI').updateMask(ee.Image.constant(0))\n",
    "    \n",
    "    test_image = s1_composite.addBands(s2_composite.rename('S2ndvi'))\n",
    "    \n",
    "    # Calculate coverage\n",
    "    coverage_by_period[days] = {}\n",
    "    \n",
    "    for band_name in ['VV', 'VH', 'S2ndvi']:\n",
    "        band = test_image.select(band_name)\n",
    "        valid_mask = band.mask()\n",
    "        \n",
    "        stats = valid_mask.reduceRegion(\n",
    "            reducer=ee.Reducer.sum().combine(\n",
    "                reducer2=ee.Reducer.count(),\n",
    "                sharedInputs=True\n",
    "            ),\n",
    "            geometry=study_area,\n",
    "            scale=SCALE,\n",
    "            maxPixels=1e10\n",
    "        ).getInfo()\n",
    "        \n",
    "        valid_pixels = stats.get(f'{band_name}_sum', 0)\n",
    "        total_pixels = stats.get(f'{band_name}_count', 1)\n",
    "        coverage_pct = (valid_pixels / total_pixels * 100) if total_pixels > 0 else 0\n",
    "        \n",
    "        coverage_by_period[days][band_name] = coverage_pct\n",
    "        print(f\"   {band_name:8s}: {coverage_pct:5.1f}% coverage\")\n",
    "\n",
    "# Summary comparison\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìä COVERAGE COMPARISON\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(f\"{'Period':>8s} {'S1 VV':>8s} {'S1 VH':>8s} {'S2 NDVI':>10s} {'Avg S1':>8s} {'Recommendation':>20s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for days in test_periods:\n",
    "    vv_cov = coverage_by_period[days]['VV']\n",
    "    vh_cov = coverage_by_period[days]['VH']\n",
    "    s2_cov = coverage_by_period[days]['S2ndvi']\n",
    "    avg_s1 = (vv_cov + vh_cov) / 2\n",
    "    \n",
    "    if s2_cov >= 95:\n",
    "        rec = \"‚úÖ Excellent\"\n",
    "    elif s2_cov >= 85:\n",
    "        rec = \"‚ö° Good\"\n",
    "    elif s2_cov >= 70:\n",
    "        rec = \"‚ö†Ô∏è  Moderate\"\n",
    "    else:\n",
    "        rec = \"‚ùå Poor\"\n",
    "    \n",
    "    print(f\"{days:>8d} {vv_cov:>7.1f}% {vh_cov:>7.1f}% {s2_cov:>9.1f}% {avg_s1:>7.1f}% {rec:>20s}\")\n",
    "\n",
    "# Recommendation\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üí° RECOMMENDATION\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Find optimal period length\n",
    "s2_coverages = [(days, coverage_by_period[days]['S2ndvi']) for days in test_periods]\n",
    "optimal = max(s2_coverages, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Based on coverage analysis:\")\n",
    "print(f\"   ‚Ä¢ Current setting: 12-day composites\")\n",
    "print(f\"   ‚Ä¢ Best coverage: {optimal[0]}-day composites ({optimal[1]:.1f}% S2 coverage)\")\n",
    "\n",
    "if optimal[1] < 85:\n",
    "    print(f\"\\n‚ö†Ô∏è  Even {optimal[0]} days gives <85% S2 coverage\")\n",
    "    print(\"   This is expected for tropical Indonesia (frequent clouds)\")\n",
    "    print(\"\\n   Options:\")\n",
    "    print(\"   1. Use monthly composites (30 days) for reliable coverage\")\n",
    "    print(\"   2. Accept gaps - MOGPR fusion designed to handle this\")\n",
    "    print(\"   3. Increase MAX_CLOUD_COVER threshold (currently 20%)\")\n",
    "    print(\"   4. Rely more on S1 data (all-weather)\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Recommended period length: {optimal[0]} days\")\n",
    "    \n",
    "    if optimal[0] != 12:\n",
    "        print(f\"\\n   To use {optimal[0]}-day periods:\")\n",
    "        print(f\"   1. Go back to Section 3\")\n",
    "        print(f\"   2. Modify generate_12day_periods() function\")\n",
    "        print(f\"   3. Change period_num * 12 to period_num * {optimal[0]}\")\n",
    "        print(f\"   4. Adjust total number of periods for the year\")\n",
    "        print(f\"   5. Re-run from Section 3 onwards\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üîÑ Or continue with 12-day periods and let MOGPR handle gaps\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5e. CRITICAL: Diagnose S2 Coverage Problem\n",
    "\n",
    "‚ö†Ô∏è **If S2 coverage is < 5% even with 30-day periods, there's a fundamental issue!**\n",
    "\n",
    "This section will diagnose why Sentinel-2 data is not appearing in the composites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSE S2 COVERAGE PROBLEM\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç DIAGNOSING SENTINEL-2 COVERAGE ISSUE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Your results show S2 NDVI = 0.1% coverage even with 30 days!\")\n",
    "print(\"   This is NOT normal. Let's investigate...\\n\")\n",
    "\n",
    "test_start = '2024-11-01'\n",
    "test_end = '2024-11-30'\n",
    "\n",
    "print(f\"Testing period: {test_start} to {test_end} (30 days)\")\n",
    "print(f\"Study area: {STUDY_AREA_TYPE.upper()}\\n\")\n",
    "\n",
    "# Step 1: Check raw S2 data availability (before cloud masking)\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: Check raw Sentinel-2 data availability\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s2_raw = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "          .filterBounds(study_area)\n",
    "          .filterDate(test_start, test_end))\n",
    "\n",
    "s2_count_raw = s2_raw.size().getInfo()\n",
    "print(f\"\\n‚úÖ Raw S2 images found (no filters): {s2_count_raw}\")\n",
    "\n",
    "if s2_count_raw == 0:\n",
    "    print(\"‚ùå PROBLEM: No Sentinel-2 images found for this area/period!\")\n",
    "    print(\"   Possible causes:\")\n",
    "    print(\"   ‚Ä¢ Study area outside S2 coverage\")\n",
    "    print(\"   ‚Ä¢ Date range has no S2 data\")\n",
    "    print(\"   ‚Ä¢ GEE data availability issue\")\n",
    "    print(\"\\nüí° Try a different date range or check study area bounds\")\n",
    "else:\n",
    "    # Get sample image info\n",
    "    sample_image = s2_raw.first()\n",
    "    sample_info = sample_image.getInfo()\n",
    "    print(f\"   First image date: {sample_info['properties'].get('system:index', 'unknown')}\")\n",
    "    print(f\"   Cloud cover: {sample_info['properties'].get('CLOUDY_PIXEL_PERCENTAGE', 'unknown')}%\")\n",
    "\n",
    "# Step 2: Check after cloud cover filtering\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Check after cloud cover filtering\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s2_cloud_filtered = s2_raw.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', MAX_CLOUD_COVER))\n",
    "s2_count_cloud = s2_cloud_filtered.size().getInfo()\n",
    "\n",
    "print(f\"\\n   Max cloud cover threshold: {MAX_CLOUD_COVER}%\")\n",
    "print(f\"   Images after cloud filtering: {s2_count_cloud}\")\n",
    "print(f\"   Images removed by cloud filter: {s2_count_raw - s2_count_cloud}\")\n",
    "\n",
    "if s2_count_cloud == 0 and s2_count_raw > 0:\n",
    "    print(\"\\n‚ùå PROBLEM: All images filtered out due to cloud cover!\")\n",
    "    print(\"   Your MAX_CLOUD_COVER = 20% is too strict for tropical Indonesia\")\n",
    "    print(\"\\nüí° SOLUTIONS:\")\n",
    "    print(\"   1. Increase MAX_CLOUD_COVER to 50-80% (recommended for Indonesia)\")\n",
    "    print(\"   2. Use longer composite periods (30+ days)\")\n",
    "    print(\"   3. Accept that cloud masking will remove cloudy pixels\")\n",
    "\n",
    "# Step 3: Check after cloud masking (pixel-level)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Check pixel-level cloud masking effect\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if s2_count_cloud > 0:\n",
    "    # Test with and without cloud masking\n",
    "    s2_no_mask = s2_cloud_filtered.map(lambda img: img.normalizedDifference(['B8', 'B4']).rename('NDVI'))\n",
    "    s2_with_mask = s2_cloud_filtered.map(lambda img: img.normalizedDifference(['B8', 'B4']).rename('NDVI')).map(\n",
    "        lambda img: img.updateMask(img.select('B8').mask())\n",
    "    )\n",
    "    \n",
    "    # Actually, let's check the SCL masking function\n",
    "    def mask_clouds_test(image):\n",
    "        scl = image.select('SCL')\n",
    "        # Keep vegetation, soil, water, snow classes (4,5,6,11)\n",
    "        good_pixels = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(11))\n",
    "        return image.updateMask(good_pixels)\n",
    "    \n",
    "    s2_scl_masked = s2_cloud_filtered.map(mask_clouds_test).map(\n",
    "        lambda img: img.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    )\n",
    "    \n",
    "    # Create composites\n",
    "    composite_no_mask = s2_no_mask.median()\n",
    "    composite_scl_mask = s2_scl_masked.median()\n",
    "    \n",
    "    # Check coverage\n",
    "    for name, composite in [('Without pixel masking', composite_no_mask), \n",
    "                             ('With SCL cloud masking', composite_scl_mask)]:\n",
    "        valid_mask = composite.mask()\n",
    "        stats = valid_mask.reduceRegion(\n",
    "            reducer=ee.Reducer.sum().combine(reducer2=ee.Reducer.count(), sharedInputs=True),\n",
    "            geometry=study_area,\n",
    "            scale=SCALE,\n",
    "            maxPixels=1e10\n",
    "        ).getInfo()\n",
    "        \n",
    "        valid_pixels = stats.get('NDVI_sum', 0)\n",
    "        total_pixels = stats.get('NDVI_count', 1)\n",
    "        coverage_pct = (valid_pixels / total_pixels * 100) if total_pixels > 0 else 0\n",
    "        \n",
    "        print(f\"\\n   {name}:\")\n",
    "        print(f\"   Coverage: {coverage_pct:.1f}%\")\n",
    "        print(f\"   Valid pixels: {int(valid_pixels):,} / {int(total_pixels):,}\")\n",
    "    \n",
    "    if coverage_pct < 10:\n",
    "        print(\"\\n‚ùå CRITICAL: SCL cloud masking removes almost everything!\")\n",
    "        print(\"   The SCL band is too aggressive for this area/period\")\n",
    "        print(\"\\nüí° SOLUTIONS:\")\n",
    "        print(\"   1. Remove SCL masking (use QA60 band instead)\")\n",
    "        print(\"   2. Use less strict SCL classes (add classes 7,8,9,10)\")\n",
    "        print(\"   3. Increase composite period to 60+ days\")\n",
    "        print(\"   4. Accept lower quality data in exchange for coverage\")\n",
    "\n",
    "# Step 4: Check if it's a date range issue\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: Check historical S2 data availability\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nChecking S2 availability for different months in 2024-2025:\")\n",
    "\n",
    "test_months = [\n",
    "    ('2024-11-01', '2024-11-30', 'Nov 2024 (rainy season)'),\n",
    "    ('2025-01-01', '2025-01-31', 'Jan 2025 (rainy season)'),\n",
    "    ('2025-04-01', '2025-04-30', 'Apr 2025 (dry season)'),\n",
    "    ('2025-07-01', '2025-07-31', 'Jul 2025 (dry season)'),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Period':<30s} {'Raw Images':>12s} {'<{MAX_CLOUD_COVER}% cloud':>15s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for start, end, label in test_months:\n",
    "    s2_test = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "               .filterBounds(study_area)\n",
    "               .filterDate(start, end))\n",
    "    \n",
    "    count_raw = s2_test.size().getInfo()\n",
    "    count_filtered = s2_test.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', MAX_CLOUD_COVER)).size().getInfo()\n",
    "    \n",
    "    print(f\"{label:<30s} {count_raw:>12d} {count_filtered:>15d}\")\n",
    "\n",
    "print(\"\\nüí° If dry season months have more images, consider:\")\n",
    "print(\"   ‚Ä¢ Using seasonal composite periods (longer in rainy season)\")\n",
    "print(\"   ‚Ä¢ Accepting higher cloud cover in rainy months\")\n",
    "\n",
    "# FINAL RECOMMENDATION\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ RECOMMENDED FIXES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nBased on your 0.1% S2 coverage, the issue is likely:\")\n",
    "print(\"\\n1. ‚ùå SCL cloud masking is TOO AGGRESSIVE\")\n",
    "print(\"   Current code removes pixels with clouds/shadows/cirrus\")\n",
    "print(\"   For Indonesia, this removes ~99% of pixels!\")\n",
    "\n",
    "print(\"\\n2. üí° IMMEDIATE FIX - Modify Section 4:\")\n",
    "print(\"   Change the mask_clouds() function to be less aggressive:\")\n",
    "print(\"\"\"\n",
    "   def mask_clouds(image):\n",
    "       # Option A: Don't use SCL masking at all\n",
    "       return image\n",
    "       \n",
    "       # Option B: Use QA60 band instead (less aggressive)\n",
    "       qa = image.select('QA60')\n",
    "       cloudBitMask = 1 << 10\n",
    "       cirrusBitMask = 1 << 11\n",
    "       mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(\n",
    "              qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "       return image.updateMask(mask)\n",
    "   \"\"\")\n",
    "\n",
    "print(\"\\n3. üí° ALTERNATIVE FIX:\")\n",
    "print(\"   Increase MAX_CLOUD_COVER from 20% to 60-80%\")\n",
    "print(\"   Then let cloud masking remove only the worst pixels\")\n",
    "\n",
    "print(\"\\n4. ‚úÖ FOR TROPICAL AREAS:\")\n",
    "print(\"   ‚Ä¢ Use 30-60 day composites\")\n",
    "print(\"   ‚Ä¢ MAX_CLOUD_COVER = 60-80%\")\n",
    "print(\"   ‚Ä¢ Less aggressive cloud masking\")\n",
    "print(\"   ‚Ä¢ Rely more on S1 data (cloud-penetrating)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5f. QUICK FIX: Update Cloud Masking Parameters\n",
    "\n",
    "Based on the diagnosis above, apply one of these fixes and re-run from Section 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# APPLY QUICK FIX FOR S2 COVERAGE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîß APPLYING FIX FOR LOW S2 COVERAGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Choose your fix approach:\n",
    "FIX_APPROACH = 'relaxed_scl'  # Options: 'no_masking', 'qa60_masking', 'relaxed_scl', 'increase_threshold'\n",
    "\n",
    "print(f\"\\nSelected approach: {FIX_APPROACH}\\n\")\n",
    "\n",
    "if FIX_APPROACH == 'no_masking':\n",
    "    # ========================================================================\n",
    "    # OPTION 1: Remove cloud masking entirely (fastest coverage)\n",
    "    # ========================================================================\n",
    "    print(\"‚úÖ Option 1: NO CLOUD MASKING\")\n",
    "    print(\"   ‚Ä¢ Fastest coverage (95-100%)\")\n",
    "    print(\"   ‚Ä¢ May include some cloudy pixels\")\n",
    "    print(\"   ‚Ä¢ Good for MOGPR (it handles outliers)\")\n",
    "    \n",
    "    def load_sentinel2_data_FIXED(geometry, start_date, end_date, max_cloud_cover=20):\n",
    "        def calculate_ndvi(image):\n",
    "            ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "            return image.addBands(ndvi)\n",
    "        \n",
    "        s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                        .filterBounds(geometry)\n",
    "                        .filterDate(start_date, end_date)\n",
    "                        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "                        .map(calculate_ndvi)\n",
    "                        .select(['NDVI']))\n",
    "        \n",
    "        return s2_collection\n",
    "    \n",
    "elif FIX_APPROACH == 'qa60_masking':\n",
    "    # ========================================================================\n",
    "    # OPTION 2: Use QA60 band instead of SCL (less aggressive)\n",
    "    # ========================================================================\n",
    "    print(\"‚úÖ Option 2: QA60 CLOUD MASKING\")\n",
    "    print(\"   ‚Ä¢ Less aggressive than SCL\")\n",
    "    print(\"   ‚Ä¢ Masks only opaque clouds and cirrus\")\n",
    "    print(\"   ‚Ä¢ Better coverage for tropical areas\")\n",
    "    \n",
    "    def load_sentinel2_data_FIXED(geometry, start_date, end_date, max_cloud_cover=20):\n",
    "        def calculate_ndvi(image):\n",
    "            ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "            return image.addBands(ndvi)\n",
    "        \n",
    "        def mask_clouds_qa60(image):\n",
    "            qa = image.select('QA60')\n",
    "            # Bits 10 and 11 are clouds and cirrus\n",
    "            cloudBitMask = 1 << 10\n",
    "            cirrusBitMask = 1 << 11\n",
    "            # Both flags should be set to zero (clear)\n",
    "            mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(\n",
    "                   qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "            return image.updateMask(mask)\n",
    "        \n",
    "        s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                        .filterBounds(geometry)\n",
    "                        .filterDate(start_date, end_date)\n",
    "                        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "                        .map(mask_clouds_qa60)\n",
    "                        .map(calculate_ndvi)\n",
    "                        .select(['NDVI']))\n",
    "        \n",
    "        return s2_collection\n",
    "    \n",
    "elif FIX_APPROACH == 'relaxed_scl':\n",
    "    # ========================================================================\n",
    "    # OPTION 3: Relaxed SCL masking (keep more pixels)\n",
    "    # ========================================================================\n",
    "    print(\"‚úÖ Option 3: RELAXED SCL MASKING\")\n",
    "    print(\"   ‚Ä¢ Keeps more pixel classes than original\")\n",
    "    print(\"   ‚Ä¢ Includes some cloud shadows and dark pixels\")\n",
    "    print(\"   ‚Ä¢ Better balance for Indonesia\")\n",
    "    \n",
    "    def load_sentinel2_data_FIXED(geometry, start_date, end_date, max_cloud_cover=20):\n",
    "        def calculate_ndvi(image):\n",
    "            ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "            return image.addBands(ndvi)\n",
    "        \n",
    "        def mask_clouds_relaxed(image):\n",
    "            scl = image.select('SCL')\n",
    "            # Keep more classes: 4,5,6,7,11 (vegetation, soil, water, dark pixels, snow)\n",
    "            # Original only kept 4,5,6,11\n",
    "            good_pixels = (scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6))\n",
    "                          .Or(scl.eq(7)).Or(scl.eq(11)))\n",
    "            return image.updateMask(good_pixels)\n",
    "        \n",
    "        s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                        .filterBounds(geometry)\n",
    "                        .filterDate(start_date, end_date)\n",
    "                        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "                        .map(mask_clouds_relaxed)\n",
    "                        .map(calculate_ndvi)\n",
    "                        .select(['NDVI']))\n",
    "        \n",
    "        return s2_collection\n",
    "\n",
    "elif FIX_APPROACH == 'increase_threshold':\n",
    "    # ========================================================================\n",
    "    # OPTION 4: Increase cloud cover threshold + original masking\n",
    "    # ========================================================================\n",
    "    print(\"‚úÖ Option 4: INCREASED CLOUD THRESHOLD\")\n",
    "    print(\"   ‚Ä¢ MAX_CLOUD_COVER increased to 60%\")\n",
    "    print(\"   ‚Ä¢ More images available for compositing\")\n",
    "    print(\"   ‚Ä¢ SCL masking removes cloudy pixels\")\n",
    "    \n",
    "    # Update global variable\n",
    "    MAX_CLOUD_COVER = 60\n",
    "    \n",
    "    def load_sentinel2_data_FIXED(geometry, start_date, end_date, max_cloud_cover=60):\n",
    "        def calculate_ndvi(image):\n",
    "            ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "            return image.addBands(ndvi)\n",
    "        \n",
    "        def mask_clouds(image):\n",
    "            scl = image.select('SCL')\n",
    "            good_pixels = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(11))\n",
    "            return image.updateMask(good_pixels)\n",
    "        \n",
    "        s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                        .filterBounds(geometry)\n",
    "                        .filterDate(start_date, end_date)\n",
    "                        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "                        .map(mask_clouds)\n",
    "                        .map(calculate_ndvi)\n",
    "                        .select(['NDVI']))\n",
    "        \n",
    "        return s2_collection\n",
    "\n",
    "# Test the fix\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß™ Testing the fix with 30-day period...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_start = '2024-11-01'\n",
    "test_end = '2024-11-30'\n",
    "\n",
    "s2_fixed = load_sentinel2_data_FIXED(study_area, test_start, test_end, MAX_CLOUD_COVER)\n",
    "s2_count_fixed = s2_fixed.size().getInfo()\n",
    "\n",
    "print(f\"\\nS2 images found: {s2_count_fixed}\")\n",
    "\n",
    "if s2_count_fixed > 0:\n",
    "    s2_composite_fixed = create_composite(s2_fixed, 'median')\n",
    "    \n",
    "    # Check coverage\n",
    "    valid_mask = s2_composite_fixed.mask()\n",
    "    stats = valid_mask.reduceRegion(\n",
    "        reducer=ee.Reducer.sum().combine(reducer2=ee.Reducer.count(), sharedInputs=True),\n",
    "        geometry=study_area,\n",
    "        scale=SCALE,\n",
    "        maxPixels=1e10\n",
    "    ).getInfo()\n",
    "    \n",
    "    valid_pixels = stats.get('NDVI_sum', 0)\n",
    "    total_pixels = stats.get('NDVI_count', 1)\n",
    "    coverage_pct = (valid_pixels / total_pixels * 100) if total_pixels > 0 else 0\n",
    "    \n",
    "    print(f\"\\n‚úÖ FIXED S2 NDVI Coverage: {coverage_pct:.1f}%\")\n",
    "    print(f\"   Valid pixels: {int(valid_pixels):,} / {int(total_pixels):,}\")\n",
    "    \n",
    "    if coverage_pct > 80:\n",
    "        print(f\"\\nüéâ SUCCESS! Coverage improved from 0.1% to {coverage_pct:.1f}%\")\n",
    "        print(\"\\nüìã NEXT STEPS:\")\n",
    "        print(\"   1. The load_sentinel2_data_FIXED() function is now defined\")\n",
    "        print(\"   2. Go back to Section 4 (Data Loading Functions)\")\n",
    "        print(\"   3. Replace load_sentinel2_data() with load_sentinel2_data_FIXED()\")\n",
    "        print(\"   4. Re-run Section 5 (Process Data)\")\n",
    "        print(\"   5. Export with full S2 coverage!\")\n",
    "    elif coverage_pct > 50:\n",
    "        print(f\"\\n‚ö° IMPROVED! Coverage increased from 0.1% to {coverage_pct:.1f}%\")\n",
    "        print(\"   Consider trying a different approach for even better coverage\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Still low coverage ({coverage_pct:.1f}%)\")\n",
    "        print(\"   Try a different FIX_APPROACH\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No S2 images found\")\n",
    "    print(\"   Try FIX_APPROACH = 'increase_threshold'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5g. ADVANCED FIX: Use S2 Cloud Probability\n",
    "\n",
    "Instead of SCL masking, use Sentinel-2 Cloud Probability for more nuanced cloud detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ADVANCED: CLOUD PROBABILITY MASKING (Most flexible approach)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üå•Ô∏è  ADVANCED CLOUD MASKING: Using S2 Cloud Probability\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüí° This approach uses a dedicated cloud probability dataset\")\n",
    "print(\"   that gives you fine control over cloud masking threshold\\n\")\n",
    "\n",
    "# Cloud probability threshold (0-100%)\n",
    "CLOUD_PROBABILITY_THRESHOLD = 50  # Adjust this: lower = stricter, higher = more data\n",
    "\n",
    "print(f\"Cloud probability threshold: {CLOUD_PROBABILITY_THRESHOLD}%\")\n",
    "print(\"   ‚Ä¢ 50% = balanced (recommended for Indonesia)\")\n",
    "print(\"   ‚Ä¢ 30% = strict (clearer data, less coverage)\")\n",
    "print(\"   ‚Ä¢ 70% = relaxed (more coverage, some clouds)\")\n",
    "\n",
    "def load_sentinel2_data_CLOUD_PROB(geometry, start_date, end_date, max_cloud_cover=60):\n",
    "    \"\"\"\n",
    "    Load Sentinel-2 data using cloud probability masking\n",
    "    More flexible than SCL-based masking\n",
    "    \"\"\"\n",
    "    \n",
    "    def calculate_ndvi(image):\n",
    "        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        return image.addBands(ndvi)\n",
    "    \n",
    "    def mask_clouds_with_probability(image):\n",
    "        # Join S2 image with its cloud probability\n",
    "        # Use a filter to find matching cloud probability image\n",
    "        cloud_prob = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "                     .filterBounds(image.geometry())\n",
    "                     .filterDate(image.date(), image.date().advance(1, 'day'))\n",
    "                     .first())\n",
    "        \n",
    "        # Get cloud probability band\n",
    "        cloud = cloud_prob.select('probability')\n",
    "        \n",
    "        # Mask pixels with cloud probability > threshold\n",
    "        is_not_cloud = cloud.lt(CLOUD_PROBABILITY_THRESHOLD)\n",
    "        \n",
    "        # Also mask cloud shadows using simple approach\n",
    "        # Shadows are typically dark in NIR\n",
    "        is_not_shadow = image.select('B8').gt(1000)  # NIR > 1000\n",
    "        \n",
    "        # Combine masks\n",
    "        final_mask = is_not_cloud.And(is_not_shadow)\n",
    "        \n",
    "        return image.updateMask(final_mask)\n",
    "    \n",
    "    # Load S2 data\n",
    "    s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                    .filterBounds(geometry)\n",
    "                    .filterDate(start_date, end_date)\n",
    "                    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "                    .map(mask_clouds_with_probability)\n",
    "                    .map(calculate_ndvi)\n",
    "                    .select(['NDVI']))\n",
    "    \n",
    "    return s2_collection\n",
    "\n",
    "# Test cloud probability masking\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß™ Testing Cloud Probability Masking (30-day period)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_start = '2024-11-01'\n",
    "test_end = '2024-11-30'\n",
    "\n",
    "try:\n",
    "    s2_cloud_prob = load_sentinel2_data_CLOUD_PROB(\n",
    "        study_area, \n",
    "        test_start, \n",
    "        test_end, \n",
    "        max_cloud_cover=60\n",
    "    )\n",
    "    \n",
    "    s2_count_prob = s2_cloud_prob.size().getInfo()\n",
    "    print(f\"\\nS2 images found: {s2_count_prob}\")\n",
    "    \n",
    "    if s2_count_prob > 0:\n",
    "        s2_composite_prob = create_composite(s2_cloud_prob, 'median')\n",
    "        \n",
    "        # Check coverage\n",
    "        valid_mask = s2_composite_prob.mask()\n",
    "        stats = valid_mask.reduceRegion(\n",
    "            reducer=ee.Reducer.sum().combine(\n",
    "                reducer2=ee.Reducer.count(), \n",
    "                sharedInputs=True\n",
    "            ),\n",
    "            geometry=study_area,\n",
    "            scale=SCALE,\n",
    "            maxPixels=1e10\n",
    "        ).getInfo()\n",
    "        \n",
    "        valid_pixels = stats.get('NDVI_sum', 0)\n",
    "        total_pixels = stats.get('NDVI_count', 1)\n",
    "        coverage_pct = (valid_pixels / total_pixels * 100) if total_pixels > 0 else 0\n",
    "        \n",
    "        print(f\"\\n‚úÖ Cloud Probability S2 Coverage: {coverage_pct:.1f}%\")\n",
    "        print(f\"   Valid pixels: {int(valid_pixels):,} / {int(total_pixels):,}\")\n",
    "        \n",
    "        if coverage_pct > 80:\n",
    "            print(f\"\\nüéâ EXCELLENT! Cloud probability masking gives {coverage_pct:.1f}% coverage\")\n",
    "            print(\"\\nüí° You can fine-tune by adjusting:\")\n",
    "            print(f\"   ‚Ä¢ CLOUD_PROBABILITY_THRESHOLD (currently {CLOUD_PROBABILITY_THRESHOLD}%)\")\n",
    "            print(f\"   ‚Ä¢ Lower threshold = stricter masking = less coverage\")\n",
    "            print(f\"   ‚Ä¢ Higher threshold = relaxed masking = more coverage\")\n",
    "        elif coverage_pct > 60:\n",
    "            print(f\"\\n‚ö° GOOD! Coverage is {coverage_pct:.1f}%\")\n",
    "            print(f\"   Try increasing CLOUD_PROBABILITY_THRESHOLD to {CLOUD_PROBABILITY_THRESHOLD + 10}% for more coverage\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Coverage still low ({coverage_pct:.1f}%)\")\n",
    "            print(\"   Try increasing CLOUD_PROBABILITY_THRESHOLD or use 'no_masking' approach\")\n",
    "            \n",
    "    else:\n",
    "        print(\"\\n‚ùå No S2 images found after filtering\")\n",
    "        print(\"   Try increasing max_cloud_cover parameter\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error testing cloud probability masking: {e}\")\n",
    "    print(\"   The cloud probability collection might not have data for all S2 images\")\n",
    "    print(\"   Fall back to QA60 or relaxed SCL masking\")\n",
    "\n",
    "# Comparison table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä CLOUD MASKING APPROACHES COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "{'Approach':<25s} {'Complexity':>12s} {'Coverage':>12s} {'Quality':>12s}\n",
    "{'-'*70}\n",
    "{'No masking':<25s} {'Simple':>12s} {'~95-100%':>12s} {'Lower':>12s}\n",
    "{'QA60 bands':<25s} {'Simple':>12s} {'~70-90%':>12s} {'Good':>12s}\n",
    "{'Relaxed SCL':<25s} {'Simple':>12s} {'~60-80%':>12s} {'Good':>12s}\n",
    "{'Cloud Probability':<25s} {'Advanced':>12s} {'~70-95%':>12s} {'Best':>12s}\n",
    "{'Original SCL':<25s} {'Simple':>12s} {'~0.1%':>12s} {'Unusable':>12s}\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüí° RECOMMENDATIONS:\")\n",
    "print(\"   For Kabupaten Demak (tropical, agricultural):\")\n",
    "print(\"   1. Best: Cloud Probability (threshold=50-60%)\")\n",
    "print(\"   2. Good: QA60 masking\")\n",
    "print(\"   3. Fast: No masking (let MOGPR handle outliers)\")\n",
    "print(\"\\n   For final export, use approach that gives >70% coverage\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_timeseries_to_drive(collection, geometry, scale, output_name):\n",
    "    \"\"\"\n",
    "    Export the time series collection to Google Drive as a multi-band image\n",
    "    \"\"\"\n",
    "    # Convert collection to multi-band image\n",
    "    # Each period becomes a separate set of bands\n",
    "    image_list = collection.toList(collection.size())\n",
    "    \n",
    "    def rename_bands_with_period(image):\n",
    "        image = ee.Image(image)\n",
    "        period = ee.Number(image.get('period')).format('%02d')\n",
    "        \n",
    "        # Rename bands to include period number\n",
    "        old_names = image.bandNames()\n",
    "        new_names = old_names.map(lambda name: ee.String(name).cat('_P').cat(period))\n",
    "        \n",
    "        return image.rename(new_names)\n",
    "    \n",
    "    # Rename bands with period numbers\n",
    "    renamed_collection = collection.map(rename_bands_with_period)\n",
    "    \n",
    "    # Convert to single multi-band image\n",
    "    multi_band_image = renamed_collection.toBands()\n",
    "    \n",
    "    # Export task\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=multi_band_image,\n",
    "        description=output_name,\n",
    "        folder='GEE_FuseTS_Data',\n",
    "        fileNamePrefix=output_name,\n",
    "        scale=scale,\n",
    "        region=geometry,\n",
    "        maxPixels=1e9,\n",
    "        crs='EPSG:4326',\n",
    "        fileFormat='GeoTIFF'\n",
    "    )\n",
    "    \n",
    "    return task\n",
    "\n",
    "def export_individual_periods_to_drive(collection, geometry, scale, base_name):\n",
    "    \"\"\"\n",
    "    Export each period as a separate GeoTIFF file to Google Drive\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    image_list = collection.toList(collection.size())\n",
    "    \n",
    "    for i in range(len(successful_periods)):\n",
    "        image = ee.Image(image_list.get(i))\n",
    "        period_num = successful_periods[i]['period']\n",
    "        \n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=image,\n",
    "            description=f'{base_name}_Period_{period_num:02d}',\n",
    "            folder='GEE_FuseTS_Data',\n",
    "            fileNamePrefix=f'{base_name}_Period_{period_num:02d}',\n",
    "            scale=scale,\n",
    "            region=geometry,\n",
    "            maxPixels=1e9,\n",
    "            crs='EPSG:4326',\n",
    "            fileFormat='GeoTIFF'\n",
    "        )\n",
    "        \n",
    "        tasks.append(task)\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "# ============================================================================\n",
    "# NEW: GEE ASSETS EXPORT FUNCTIONS (Better for large datasets!)\n",
    "# ============================================================================\n",
    "\n",
    "def export_timeseries_to_asset(collection, geometry, scale, asset_id):\n",
    "    \"\"\"\n",
    "    Export the time series collection to GEE Assets as ImageCollection\n",
    "    \n",
    "    Advantages over Drive export:\n",
    "    - No size limits (up to 10TB per user)\n",
    "    - Data stays in GEE cloud (faster processing)\n",
    "    - Can be used immediately in other GEE scripts\n",
    "    - Better for large study areas\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    asset_id : str\n",
    "        Full path to asset, e.g., 'projects/ee-geodeticengineeringundip/assets/S1_S2_Nov2024_Oct2025'\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    image_list = collection.toList(collection.size())\n",
    "    \n",
    "    for i in range(len(successful_periods)):\n",
    "        image = ee.Image(image_list.get(i))\n",
    "        period_num = successful_periods[i]['period']\n",
    "        period_info = successful_periods[i]\n",
    "        \n",
    "        # Add comprehensive metadata\n",
    "        image_with_metadata = image.set({\n",
    "            'period': period_num,\n",
    "            'start_date': period_info['start_str'],\n",
    "            'end_date': period_info['end_str'],\n",
    "            'center_date': period_info['center_date'].strftime('%Y-%m-%d'),\n",
    "            'doy_center': period_info['doy_center'],\n",
    "            'year': period_info['year'],\n",
    "            'month': period_info['month'],\n",
    "            'system:time_start': ee.Date(period_info['start_str']).millis(),\n",
    "            'system:time_end': ee.Date(period_info['end_str']).millis()\n",
    "        })\n",
    "        \n",
    "        # Create asset ID for this period\n",
    "        period_asset_id = f'{asset_id}_Period_{period_num:02d}'\n",
    "        \n",
    "        task = ee.batch.Export.image.toAsset(\n",
    "            image=image_with_metadata,\n",
    "            description=f'Asset_Period_{period_num:02d}',\n",
    "            assetId=period_asset_id,\n",
    "            scale=scale,\n",
    "            region=geometry,\n",
    "            maxPixels=1e13,  # Higher limit for assets\n",
    "            crs='EPSG:4326',\n",
    "            pyramidingPolicy={'.default': 'mean'}  # Better for time series\n",
    "        )\n",
    "        \n",
    "        tasks.append(task)\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "def export_imagecollection_to_asset(collection, asset_id, geometry, scale):\n",
    "    \"\"\"\n",
    "    Export entire ImageCollection to a single GEE Asset\n",
    "    \n",
    "    Note: For very large collections, individual image exports (above function) are more reliable\n",
    "    \"\"\"\n",
    "    # This exports the collection metadata structure\n",
    "    # Individual images still need to be exported separately\n",
    "    print(\"‚ö†Ô∏è  GEE doesn't support direct ImageCollection export.\")\n",
    "    print(\"    Use export_timeseries_to_asset() to export individual images.\")\n",
    "    print(\"    They will form an ImageCollection when all are in the same folder.\")\n",
    "    return None\n",
    "\n",
    "# Choose export method\n",
    "EXPORT_METHOD = 'individual'  # 'combined' or 'individual'\n",
    "EXPORT_DESTINATION = 'drive'  # 'drive' or 'asset' - CHANGED TO 'drive' due to asset quota limit\n",
    "\n",
    "# Your GEE Assets path (update this to your project!)\n",
    "ASSET_BASE_PATH = 'projects/ee-geodeticengineeringundip/assets/FuseTS'\n",
    "\n",
    "print(f\"\\nüì§ EXPORT CONFIGURATION:\")\n",
    "print(f\"   Destination: {EXPORT_DESTINATION.upper()}\")\n",
    "print(f\"   Method: {EXPORT_METHOD}\")\n",
    "if EXPORT_DESTINATION == 'asset':\n",
    "    print(f\"   Asset path: {ASSET_BASE_PATH}\")\n",
    "print(f\"\\nüí° Choose export destination:\")\n",
    "print(f\"   ‚Ä¢ 'drive': Google Drive (good for < 2GB, need to download)\")\n",
    "print(f\"   ‚Ä¢ 'asset': GEE Assets (recommended for large data, stays in cloud)\")\n",
    "\n",
    "if time_series_collection:\n",
    "    if EXPORT_DESTINATION == 'asset':\n",
    "        # ====================================================================\n",
    "        # EXPORT TO GEE ASSETS (Recommended for large datasets!)\n",
    "        # ====================================================================\n",
    "        print(\"\\nüöÄ Exporting to GEE Assets...\")\n",
    "        print(\"   ‚úÖ No size limits (up to 10TB)\")\n",
    "        print(\"   ‚úÖ Data stays in GEE cloud\")\n",
    "        print(\"   ‚úÖ Can use immediately in other scripts\")\n",
    "        \n",
    "        asset_id = f'{ASSET_BASE_PATH}/S1_S2_Nov2024_Oct2025'\n",
    "        \n",
    "        export_tasks = export_timeseries_to_asset(\n",
    "            time_series_collection,\n",
    "            study_area,\n",
    "            SCALE,\n",
    "            asset_id\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüìã Starting {len(export_tasks)} asset export tasks...\")\n",
    "        \n",
    "        # Start first 10 tasks (GEE limits concurrent tasks)\n",
    "        for i, task in enumerate(export_tasks[:10]):\n",
    "            task.start()\n",
    "            print(f\"  ‚úÖ Started: Period {i+1:02d} ‚Üí {asset_id}_Period_{i+1:02d}\")\n",
    "        \n",
    "        if len(export_tasks) > 10:\n",
    "            print(f\"\\n‚è≥ Remaining {len(export_tasks) - 10} tasks queued\")\n",
    "            print(\"   Start them manually from: https://code.earthengine.google.com/tasks\")\n",
    "            print(\"   Or run this code to start next batch:\")\n",
    "            print(f\"   for task in export_tasks[10:20]: task.start()\")\n",
    "        \n",
    "        print(f\"\\nüìä After exports complete, load data in GEE with:\")\n",
    "        print(f\"   var collection = ee.ImageCollection('{ASSET_BASE_PATH}/S1_S2_Nov2024_Oct2025_Period_*');\")\n",
    "        \n",
    "    elif EXPORT_DESTINATION == 'drive':\n",
    "        # ====================================================================\n",
    "        # EXPORT TO GOOGLE DRIVE (Original method)\n",
    "        # ====================================================================\n",
    "        if EXPORT_METHOD == 'combined':\n",
    "            # Export as single multi-band file\n",
    "            print(\"\\nüì§ Preparing export as single multi-band GeoTIFF to Google Drive...\")\n",
    "            export_task = export_timeseries_to_drive(\n",
    "                time_series_collection, \n",
    "                study_area, \n",
    "                SCALE, \n",
    "                f'S1_S2_TimeSeries_Nov2024_Oct2025'\n",
    "            )\n",
    "            \n",
    "            print(f\"Starting export task: {export_task.config['description']}\")\n",
    "            export_task.start()\n",
    "            \n",
    "            print(f\"Export task submitted. Monitor progress at: https://code.earthengine.google.com/tasks\")\n",
    "            \n",
    "        else:\n",
    "            # Export individual period files\n",
    "            print(\"\\nüì§ Preparing export as individual period GeoTIFFs to Google Drive...\")\n",
    "            export_tasks = export_individual_periods_to_drive(\n",
    "                time_series_collection,\n",
    "                study_area,\n",
    "                SCALE,\n",
    "                f'S1_S2_Nov2024_Oct2025'\n",
    "            )\n",
    "            \n",
    "            print(f\"Starting {len(export_tasks)} export tasks...\")\n",
    "            for i, task in enumerate(export_tasks[:5]):  # Start first 5 tasks\n",
    "                task.start()\n",
    "                print(f\"  Started: {task.config['description']}\")\n",
    "            \n",
    "            if len(export_tasks) > 5:\n",
    "                print(f\"\\nRemaining {len(export_tasks) - 5} tasks can be started manually or in batches\")\n",
    "                print(\"Monitor all tasks at: https://code.earthengine.google.com/tasks\")\n",
    "\n",
    "else:\n",
    "    print(\"No data to export!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Local Processing Function (Alternative to Export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6b. Load Data from GEE Assets (For Subsequent Processing)\n",
    "\n",
    "If you exported to GEE Assets, use this code to load the data later in GEE or download specific regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD DATA FROM GEE ASSETS\n",
    "# ============================================================================\n",
    "\n",
    "def load_asset_collection(asset_base_path, pattern='*'):\n",
    "    \"\"\"\n",
    "    Load ImageCollection from GEE Assets\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    asset_base_path : str\n",
    "        Base path to assets folder\n",
    "    pattern : str\n",
    "        Pattern to match asset names (e.g., 'S1_S2_Nov2024_Oct2025_Period_*')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ee.ImageCollection\n",
    "    \"\"\"\n",
    "    # Load all images matching the pattern\n",
    "    full_pattern = f'{asset_base_path}/{pattern}'\n",
    "    \n",
    "    try:\n",
    "        # Try loading as collection\n",
    "        collection = ee.ImageCollection(full_pattern)\n",
    "        count = collection.size().getInfo()\n",
    "        print(f\"‚úÖ Loaded {count} images from assets\")\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading assets: {e}\")\n",
    "        print(f\"   Make sure assets exist at: {full_pattern}\")\n",
    "        print(f\"   Check: https://code.earthengine.google.com/?asset={asset_base_path}\")\n",
    "        return None\n",
    "\n",
    "def download_region_from_assets(collection, region_geometry, scale, output_format='GeoTIFF'):\n",
    "    \"\"\"\n",
    "    Download a specific region from asset collection\n",
    "    \n",
    "    This is useful when you've exported large Java Island data but only want\n",
    "    a smaller region for analysis\n",
    "    \"\"\"\n",
    "    # Convert collection to multi-band image\n",
    "    def add_period_to_bands(image):\n",
    "        period = ee.Number(image.get('period')).format('%02d')\n",
    "        old_names = image.bandNames()\n",
    "        new_names = old_names.map(lambda name: ee.String(name).cat('_P').cat(period))\n",
    "        return image.rename(new_names)\n",
    "    \n",
    "    renamed_collection = collection.map(add_period_to_bands)\n",
    "    multi_band = renamed_collection.toBands()\n",
    "    \n",
    "    # Create download URL\n",
    "    url = multi_band.getDownloadURL({\n",
    "        'scale': scale,\n",
    "        'crs': 'EPSG:4326',\n",
    "        'region': region_geometry,\n",
    "        'format': output_format\n",
    "    })\n",
    "    \n",
    "    print(f\"üì• Download URL generated:\")\n",
    "    print(f\"   {url}\")\n",
    "    print(f\"\\n   Copy this URL to your browser to download\")\n",
    "    \n",
    "    return url\n",
    "\n",
    "# Example: Load your exported assets\n",
    "if EXPORT_DESTINATION == 'asset':\n",
    "    print(\"=\"*60)\n",
    "    print(\"üìñ LOADING DATA FROM GEE ASSETS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Wait a moment for exports to start (if just submitted)\n",
    "    import time\n",
    "    print(\"\\n‚è≥ Note: Asset exports take time. Check status at:\")\n",
    "    print(\"   https://code.earthengine.google.com/tasks\")\n",
    "    \n",
    "    # Example of how to load later (after exports complete)\n",
    "    print(f\"\\nüí° To load your exported data later, use:\")\n",
    "    print(f\"\\n```python\")\n",
    "    print(f\"# Load the asset collection\")\n",
    "    print(f\"asset_pattern = '{ASSET_BASE_PATH}/S1_S2_Nov2024_Oct2025_Period_*'\")\n",
    "    print(f\"collection = ee.ImageCollection(asset_pattern)\")\n",
    "    print(f\"\")\n",
    "    print(f\"# Check what was loaded\")\n",
    "    print(f\"print(f'Loaded {{collection.size().getInfo()}} images')\")\n",
    "    print(f\"\")\n",
    "    print(f\"# Download a specific region (optional)\")\n",
    "    print(f\"small_region = ee.Geometry.Rectangle([106.8, -6.3, 107.0, -6.1])  # Example: Jakarta area\")\n",
    "    print(f\"url = download_region_from_assets(collection, small_region, scale={SCALE})\")\n",
    "    print(f\"```\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Or use directly in GEE Code Editor:\")\n",
    "    print(f\"```javascript\")\n",
    "    print(f\"// Load the collection\")\n",
    "    print(f\"var collection = ee.ImageCollection('{ASSET_BASE_PATH}/S1_S2_Nov2024_Oct2025_Period_*');\")\n",
    "    print(f\"\")\n",
    "    print(f\"// Sort by period\")\n",
    "    print(f\"var sorted = collection.sort('period');\")\n",
    "    print(f\"\")\n",
    "    print(f\"// Get first image\")\n",
    "    print(f\"var first = sorted.first();\")\n",
    "    print(f\"print('First period bands:', first.bandNames());\")\n",
    "    print(f\"\")\n",
    "    print(f\"// Process further or export to Drive from here\")\n",
    "    print(f\"```\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Assets allow you to:\")\n",
    "    print(f\"   ‚Ä¢ Process data entirely in GEE (no download needed)\")\n",
    "    print(f\"   ‚Ä¢ Download only specific regions when needed\")\n",
    "    print(f\"   ‚Ä¢ Share with collaborators\")\n",
    "    print(f\"   ‚Ä¢ Use in GEE Code Editor or Python API\")\n",
    "\n",
    "elif EXPORT_DESTINATION == 'drive':\n",
    "    print(\"\\nüí° For Google Drive exports:\")\n",
    "    print(\"   1. Monitor tasks at: https://code.earthengine.google.com/tasks\")\n",
    "    print(\"   2. Download files from Google Drive\")\n",
    "    print(\"   3. Use local processing (Section 7 below) or load in MOGPR notebook\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timeseries_locally(collection, geometry, scale, max_pixels=1e6):\n",
    "    \"\"\"\n",
    "    Extract time series data directly to memory for small areas\n",
    "    This is faster than export/download for small study areas\n",
    "    \"\"\"\n",
    "    print(\"Extracting time series data locally...\")\n",
    "    \n",
    "    # Get the region bounds\n",
    "    region = geometry.bounds()\n",
    "    \n",
    "    # Extract data for each period\n",
    "    image_list = collection.toList(collection.size())\n",
    "    \n",
    "    periods_data = []\n",
    "    \n",
    "    for i in range(len(successful_periods)):\n",
    "        print(f\"Extracting period {i+1}/{len(successful_periods)}...\")\n",
    "        \n",
    "        image = ee.Image(image_list.get(i))\n",
    "        period_info = successful_periods[i]\n",
    "        \n",
    "        try:\n",
    "            # Sample the image\n",
    "            if scale * scale * 10000 < max_pixels:  # Rough estimate\n",
    "                # Use geemap for efficient extraction\n",
    "                data_array = geemap.ee_to_xarray(\n",
    "                    image, \n",
    "                    region=region, \n",
    "                    scale=scale,\n",
    "                    crs='EPSG:4326'\n",
    "                )\n",
    "                \n",
    "                # Add period information\n",
    "                data_array = data_array.assign_coords(\n",
    "                    period=period_info['period'],\n",
    "                    center_date=period_info['center_date'],\n",
    "                    doy_center=period_info['doy_center']\n",
    "                )\n",
    "                \n",
    "                periods_data.append(data_array)\n",
    "                \n",
    "            else:\n",
    "                print(f\"  Area too large for local extraction, use export method instead\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error extracting period {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if periods_data:\n",
    "        # Combine all periods into a single xarray Dataset\n",
    "        print(\"Combining periods into time series...\")\n",
    "        \n",
    "        # Concatenate along a new time dimension\n",
    "        combined_data = xr.concat(periods_data, dim='time')\n",
    "        \n",
    "        # Create proper time coordinates\n",
    "        time_coords = [p['center_date'] for p in successful_periods[:len(periods_data)]]\n",
    "        combined_data = combined_data.assign_coords(time=time_coords)\n",
    "        \n",
    "        return combined_data\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Try local extraction for small areas\n",
    "area_size = study_area.area().getInfo()  # in square meters\n",
    "area_km2 = area_size / 1e6\n",
    "\n",
    "print(f\"Study area size: {area_km2:.2f} km¬≤\")\n",
    "\n",
    "if area_km2 < 100:  # Less than 100 km¬≤\n",
    "    print(\"Area is small enough for local extraction. Attempting direct download...\")\n",
    "    \n",
    "    try:\n",
    "        local_data = extract_timeseries_locally(\n",
    "            time_series_collection, \n",
    "            study_area, \n",
    "            SCALE, \n",
    "            max_pixels=1e6\n",
    "        )\n",
    "        \n",
    "        if local_data is not None:\n",
    "            print(\"Local extraction successful!\")\n",
    "            print(f\"Data shape: {local_data.dims}\")\n",
    "            print(f\"Variables: {list(local_data.data_vars)}\")\n",
    "            \n",
    "            # Save locally\n",
    "            output_file = os.path.join(OUTPUT_DIR, f'S1_S2_timeseries_Nov2024_Oct2025_local.nc')\n",
    "            local_data.to_netcdf(output_file)\n",
    "            print(f\"Data saved to: {output_file}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Local extraction failed, use export method instead\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Local extraction error: {e}\")\n",
    "        print(\"Use export method instead\")\n",
    "        \n",
    "else:\n",
    "    print(\"Area is too large for local extraction. Use the export method above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Metadata and Processing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processing summary\n",
    "processing_summary = {\n",
    "    'processing_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'start_date': START_DATE,\n",
    "    'end_date': END_DATE,\n",
    "    'temporal_coverage': f'{START_DATE} to {END_DATE}',\n",
    "    'agricultural_year': 'Nov 2024 - Oct 2025',\n",
    "    'total_periods': len(periods),\n",
    "    'successful_periods': len(successful_periods),\n",
    "    'study_area_bounds': study_area.bounds().getInfo(),\n",
    "    'spatial_resolution': f'{SCALE}m',\n",
    "    'coordinate_system': CRS,\n",
    "    'max_cloud_cover': MAX_CLOUD_COVER,\n",
    "    'composite_method': 'median',\n",
    "    'output_bands': ['VV', 'VH', 'S2ndvi'],\n",
    "    'agricultural_seasons_covered': {\n",
    "        'season_1': 'Nov 2024 - Mar 2025 (first planting, crosses year boundary)',\n",
    "        'season_2': 'Apr - Jun 2025 (second planting, dry season)',\n",
    "        'season_3': 'Jul - Sep 2025 (third planting, optional intensive)',\n",
    "        'full_coverage': 'Through Oct 2025'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create detailed period information\n",
    "period_details = []\n",
    "for period in successful_periods:\n",
    "    period_details.append({\n",
    "        'period': period['period'],\n",
    "        'start_date': period['start_str'],\n",
    "        'end_date': period['end_str'],\n",
    "        'center_date': period['center_date'].strftime('%Y-%m-%d'),\n",
    "        'doy_center': period['doy_center'],\n",
    "        'year': period['year'],\n",
    "        'month': period['month']\n",
    "    })\n",
    "\n",
    "# Save metadata\n",
    "import json\n",
    "\n",
    "metadata = {\n",
    "    'summary': processing_summary,\n",
    "    'periods': period_details\n",
    "}\n",
    "\n",
    "metadata_file = os.path.join(OUTPUT_DIR, f'processing_metadata_Nov2024_Oct2025.json')\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(\"Processing Summary:\")\n",
    "print(f\"  Temporal coverage: {START_DATE} to {END_DATE}\")\n",
    "print(f\"  Agricultural year: Nov 2024 - Oct 2025\")\n",
    "print(f\"  Total periods: {len(periods)}\")\n",
    "print(f\"  Successful periods: {len(successful_periods)}\")\n",
    "print(f\"  Spatial resolution: {SCALE}m\")\n",
    "print(f\"  Coordinate system: {CRS}\")\n",
    "print(f\"  Output bands: {processing_summary['output_bands']}\")\n",
    "print(f\"\\nAgricultural Seasons Covered:\")\n",
    "print(f\"  Season 1 (Nov-Mar): First planting season (crosses 2024‚Üí2025 boundary)\")\n",
    "print(f\"  Season 2 (Apr-Jun): Second planting season (dry season)\")\n",
    "print(f\"  Season 3 (Jul-Sep): Third planting season (optional intensive)\")\n",
    "print(f\"  Full coverage: Through October 2025\")\n",
    "print(f\"\\nMetadata saved to: {metadata_file}\")\n",
    "\n",
    "# Create period visualization\n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "# Plot period timeline\n",
    "period_dates = [p['center_date'] for p in successful_periods]\n",
    "period_numbers = [p['period'] for p in successful_periods]\n",
    "\n",
    "ax.scatter(period_dates, period_numbers, alpha=0.7, s=50)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Period Number', fontsize=12)\n",
    "ax.set_title(f'12-Day Composite Periods: {START_DATE} to {END_DATE}\\nIndonesian Agricultural Year Coverage ({SCALE}m resolution, {CRS})', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add month boundaries and labels for both years\n",
    "from matplotlib.dates import DateFormatter, MonthLocator\n",
    "ax.xaxis.set_major_locator(MonthLocator())\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "\n",
    "# Highlight agricultural seasons with colored backgrounds\n",
    "from matplotlib.patches import Rectangle\n",
    "from datetime import datetime\n",
    "\n",
    "# Season 1: Nov 2024 - Mar 2025 (first planting)\n",
    "season1_start = datetime(2024, 11, 1)\n",
    "season1_end = datetime(2025, 3, 31)\n",
    "ax.axvspan(season1_start, season1_end, alpha=0.15, color='green', label='Season 1: Nov-Mar (First Planting)')\n",
    "\n",
    "# Season 2: Apr - Jun 2025 (second planting)\n",
    "season2_start = datetime(2025, 4, 1)\n",
    "season2_end = datetime(2025, 6, 30)\n",
    "ax.axvspan(season2_start, season2_end, alpha=0.15, color='blue', label='Season 2: Apr-Jun (Second Planting)')\n",
    "\n",
    "# Season 3: Jul - Sep 2025 (third planting)\n",
    "season3_start = datetime(2025, 7, 1)\n",
    "season3_end = datetime(2025, 9, 30)\n",
    "ax.axvspan(season3_start, season3_end, alpha=0.15, color='orange', label='Season 3: Jul-Sep (Third Planting)')\n",
    "\n",
    "# Highlight year boundary\n",
    "year_boundary = datetime(2025, 1, 1)\n",
    "ax.axvline(year_boundary, color='red', linewidth=2, linestyle='--', label='Year Boundary (2024‚Üí2025)')\n",
    "\n",
    "ax.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, f'period_timeline_Nov2024_Oct2025.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPeriod timeline saved to: {os.path.join(OUTPUT_DIR, f'period_timeline_Nov2024_Oct2025.png')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Conversion for FuseTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fusets_format(data_path_or_array, metadata_path=None):\n",
    "    \"\"\"\n",
    "    Convert GEE-exported data to FuseTS-compatible format\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(data_path_or_array, str):\n",
    "        # Load from file\n",
    "        print(f\"Loading data from: {data_path_or_array}\")\n",
    "        \n",
    "        if data_path_or_array.endswith('.nc'):\n",
    "            data = xr.open_dataset(data_path_or_array)\n",
    "        else:\n",
    "            # Assume GeoTIFF\n",
    "            import rioxarray\n",
    "            data = rioxarray.open_rasterio(data_path_or_array)\n",
    "            \n",
    "    else:\n",
    "        # Use provided array\n",
    "        data = data_path_or_array\n",
    "    \n",
    "    print(\"Converting to FuseTS format...\")\n",
    "    \n",
    "    # Ensure proper dimension naming\n",
    "    if 'time' in data.dims:\n",
    "        data = data.rename({'time': 't'})\n",
    "    \n",
    "    # Ensure proper band naming for FuseTS\n",
    "    if 'NDVI' in data.data_vars:\n",
    "        data = data.rename({'NDVI': 'S2ndvi'})\n",
    "    \n",
    "    # Ensure coordinate order is (t, y, x)\n",
    "    expected_dims = ['t', 'y', 'x']\n",
    "    \n",
    "    for var in data.data_vars:\n",
    "        if set(data[var].dims) == set(expected_dims):\n",
    "            data[var] = data[var].transpose('t', 'y', 'x')\n",
    "    \n",
    "    # Add FuseTS-specific attributes\n",
    "    data.attrs.update({\n",
    "        'title': f'Sentinel-1/2 Time Series for FuseTS Processing',\n",
    "        'description': '12-day composite periods extracted from Google Earth Engine',\n",
    "        'bands': 'VV (S1), VH (S1), S2ndvi (S2 NDVI)',\n",
    "        'temporal_resolution': '12-day composites',\n",
    "        'processing_software': 'Google Earth Engine + Python',\n",
    "        'fusets_ready': True\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_example_usage_script():\n",
    "    \"\"\"\n",
    "    Create a script showing how to use the exported data with FuseTS\n",
    "    \"\"\"\n",
    "    \n",
    "    script_content = '''\n",
    "# Example script to use GEE-exported data with FuseTS\n",
    "# Run this after downloading the exported data from Google Drive\n",
    "# Temporal coverage: November 2024 - October 2025 (Indonesian agricultural year)\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from fusets.mogpr import MOGPRTransformer\n",
    "from fusets.analytics import phenology\n",
    "from fusets import whittaker\n",
    "\n",
    "# Load the exported data\n",
    "# Option 1: If you exported as individual periods\n",
    "# data_files = ['S1_S2_Nov2024_Oct2025_Period_01.tif', 'S1_S2_Nov2024_Oct2025_Period_02.tif', ...]\n",
    "# data = combine_period_files(data_files)  # You'll need to implement this\n",
    "\n",
    "# Option 2: If you exported as single multi-band file\n",
    "data_path = 'S1_S2_TimeSeries_Nov2024_Oct2025.tif'\n",
    "data = rioxarray.open_rasterio(data_path)\n",
    "\n",
    "# Convert to FuseTS format\n",
    "fusets_data = prepare_fusets_format(data)\n",
    "\n",
    "# Apply MOGPR fusion\n",
    "mogpr = MOGPRTransformer()\n",
    "fused_data = mogpr.fit_transform(fusets_data)\n",
    "\n",
    "# Extract phenological metrics for Indonesian agricultural seasons\n",
    "# Season 1: Nov 2024 - Mar 2025 (first planting, crosses year boundary)\n",
    "# Season 2: Apr - Jun 2025 (second planting, dry season)\n",
    "# Season 3: Jul - Sep 2025 (third planting, optional intensive)\n",
    "\n",
    "phenology_metrics = phenology(fused_data['S2ndvi'])\n",
    "\n",
    "# Access results\n",
    "sos_times = phenology_metrics.da_sos_times\n",
    "eos_times = phenology_metrics.da_eos_times\n",
    "\n",
    "print(\"FuseTS processing completed for Nov 2024 - Oct 2025!\")\n",
    "print(\"Captured full Indonesian agricultural calendar including year-boundary season\")\n",
    "'''\n",
    "    \n",
    "    script_file = os.path.join(OUTPUT_DIR, 'fusets_processing_example.py')\n",
    "    with open(script_file, 'w') as f:\n",
    "        f.write(script_content)\n",
    "    \n",
    "    return script_file\n",
    "\n",
    "# Create example script\n",
    "example_script = create_example_usage_script()\n",
    "print(f\"Example FuseTS processing script created: {example_script}\")\n",
    "\n",
    "# If we have local data, prepare it for FuseTS\n",
    "if 'local_data' in locals() and local_data is not None:\n",
    "    print(\"\\nPreparing local data for FuseTS...\")\n",
    "    fusets_ready_data = prepare_fusets_format(local_data)\n",
    "    \n",
    "    # Save FuseTS-ready data\n",
    "    fusets_output = os.path.join(OUTPUT_DIR, f'S1_S2_timeseries_Nov2024_Oct2025_fusets_ready.nc')\n",
    "    fusets_ready_data.to_netcdf(fusets_output)\n",
    "    print(f\"FuseTS-ready data saved to: {fusets_output}\")\n",
    "    \n",
    "    # Display data structure\n",
    "    print(\"\\nFuseTS-ready data structure:\")\n",
    "    print(fusets_ready_data)\n",
    "    \n",
    "    print(\"\\nThis data is now ready for the MOGPR fusion notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### What this notebook accomplishes:\n",
    "\n",
    "1. **Temporal Strategy**: Creates exactly 31 periods of 12-day composites from **Nov 2024 to Oct 2025**\n",
    "2. **Data Collection**: Extracts S1 (VV, VH) and S2 (NDVI) data from Google Earth Engine\n",
    "3. **Cloud Processing**: Uses GEE's computational power for large-scale data processing\n",
    "4. **Flexible Export**: **GEE Assets (recommended)** or Google Drive\n",
    "5. **Local Processing**: For small areas, extracts data directly without export/download\n",
    "6. **FuseTS Preparation**: Converts data to the exact format needed for MOGPR processing\n",
    "\n",
    "### Export Options Comparison:\n",
    "\n",
    "| Feature | GEE Assets ‚≠ê RECOMMENDED | Google Drive |\n",
    "|---------|---------------------------|--------------|\n",
    "| **Size limit** | 10 TB per user | ~15 GB per file |\n",
    "| **Best for** | Large areas (Java Island) | Small test areas |\n",
    "| **Speed** | Fast (stays in cloud) | Slow (download required) |\n",
    "| **Usage** | Use directly in GEE | Must download first |\n",
    "| **Sharing** | Easy (asset permissions) | Manual file sharing |\n",
    "| **Cost** | Free (GEE quota) | Free (Drive quota) |\n",
    "| **Processing** | Process in GEE cloud | Local processing needed |\n",
    "\n",
    "### When to use GEE Assets:\n",
    "‚úÖ **Study area > 1000 km¬≤** (like Java Island with 5km buffer)  \n",
    "‚úÖ **Multiple people need access** to the same data  \n",
    "‚úÖ **Want to process in GEE** without downloading  \n",
    "‚úÖ **Need to reuse data** in multiple projects  \n",
    "‚úÖ **Data size > 2GB**  \n",
    "\n",
    "### When to use Google Drive:\n",
    "‚úÖ **Small test area** (< 100 km¬≤)  \n",
    "‚úÖ **Quick prototyping** with local tools  \n",
    "‚úÖ **One-time download** for offline work  \n",
    "‚úÖ **Prefer local storage** over cloud  \n",
    "\n",
    "### Temporal Coverage (Indonesian Agricultural Year):\n",
    "- **Period 1**: 2024-11-01 to 2024-11-12 ‚Üê **First planting season starts**\n",
    "- **Period 2**: 2024-11-13 to 2024-11-24  \n",
    "- **Period 3**: 2024-11-25 to 2024-12-06\n",
    "- **Period 6**: 2024-12-31 to 2025-01-11 ‚Üê **Crosses year boundary**\n",
    "- **...**\n",
    "- **Period 11**: 2025-03-09 to 2025-03-20 ‚Üê **First planting season ends**\n",
    "- **Period 12-18**: 2025-04-01 to 2025-06-30 ‚Üê **Second planting season**\n",
    "- **Period 19-25**: 2025-07-01 to 2025-09-30 ‚Üê **Third planting season (optional)**\n",
    "- **Period 31**: 2025-10-21 to 2025-10-31 ‚Üê **Full coverage complete**\n",
    "\n",
    "### Agricultural Seasons Captured:\n",
    "- **Season 1 (Nov-Mar)**: First planting season - **handles year boundary transition**\n",
    "  - Start: Nov 2024 (Period 1)\n",
    "  - Peak: Jan 2025 (crosses from 2024‚Üí2025)\n",
    "  - End: Mar 2025 (Period ~11)\n",
    "  \n",
    "- **Season 2 (Apr-Jun)**: Second planting season (dry season)\n",
    "  - Periods 12-18 in 2025\n",
    "  \n",
    "- **Season 3 (Jul-Sep)**: Third planting season (optional intensive)\n",
    "  - Periods 19-25 in 2025\n",
    "  \n",
    "- **Full Monitoring**: Through October 2025 (Period 31)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "#### If you exported to GEE Assets (Recommended):\n",
    "1. **Monitor exports**: https://code.earthengine.google.com/tasks\n",
    "2. **Use in GEE Code Editor**:\n",
    "   ```javascript\n",
    "   var collection = ee.ImageCollection('projects/ee-geodeticengineeringundip/assets/FuseTS/S1_S2_Nov2024_Oct2025_Period_*');\n",
    "   ```\n",
    "3. **Or download specific regions** when needed (see Section 6b)\n",
    "4. **Process in GEE** or download small regions for local analysis\n",
    "\n",
    "#### If you exported to Google Drive:\n",
    "1. **Download Data**: Monitor exports at https://code.earthengine.google.com/tasks\n",
    "2. **Load in FuseTS**: Use the exported GeoTIFF files with the MOGPR fusion notebook\n",
    "3. **Apply MOGPR**: Run the S1+S2 fusion using the prepared time series\n",
    "4. **Multi-Season Analysis**: Detect all three Indonesian agricultural seasons\n",
    "\n",
    "### File Outputs:\n",
    "- **Assets**: `projects/ee-geodeticengineeringundip/assets/FuseTS/S1_S2_Nov2024_Oct2025_Period_*`\n",
    "- **Or Drive**: S1_S2_TimeSeries_Nov2024_Oct2025.tif (or individual period files)\n",
    "- **Metadata**: processing_metadata_Nov2024_Oct2025.json\n",
    "- **Timeline**: period_timeline_Nov2024_Oct2025.png\n",
    "- **Example Script**: fusets_processing_example.py\n",
    "\n",
    "### Key Features:\n",
    "‚úÖ **Perfect alignment** with Indonesian agricultural calendar  \n",
    "‚úÖ **Year boundary handling** for Nov 2024 ‚Üí Mar 2025 first season  \n",
    "‚úÖ **Complete coverage** of all potential planting seasons  \n",
    "‚úÖ **31 periods** √ó 12 days = 365 days (full agricultural year)  \n",
    "‚úÖ **50m resolution** for efficient regional analysis  \n",
    "‚úÖ **GEE Assets support** for large-scale datasets  \n",
    "\n",
    "### For Large Datasets (Java Island):\n",
    "üí° **Recommended workflow**:\n",
    "1. Export to **GEE Assets** (no size limits)\n",
    "2. Process and analyze **entirely in GEE** using Code Editor or Python API\n",
    "3. Download **only final results** or specific regions of interest\n",
    "4. Use MOGPR fusion **on cloud-processed data** for maximum efficiency\n",
    "\n",
    "The exported data is now ready for the FuseTS MOGPR processing workflow with full Indonesian agricultural season detection!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
