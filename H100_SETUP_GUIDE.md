# H100 GPU Setup Guide for MOGPR

## üéØ Your System

- **GPUs**: 2x NVIDIA H100 80GB HBM3
- **CUDA**: 12.4
- **Driver**: 550.127.05
- **Total VRAM**: 160 GB (80GB per GPU)

## üì¶ Installation (5 minutes)

### Step 1: Upload files to HPC

```bash
# From your local machine
scp -r /Users/macbook/Dropbox/GitHub/FuseTS username@your_hpc:/path/to/workspace/
```

### Step 2: Run setup script

```bash
# SSH to HPC
ssh username@your_hpc
cd /path/to/FuseTS

# Make scripts executable
chmod +x setup_h100_mogpr.sh
chmod +x test_h100_setup.sh
chmod +x run_mogpr_h100.slurm

# Run setup
./setup_h100_mogpr.sh
```

This will:
- Create Python environment
- Install PyTorch with CUDA 12.4 support
- Install GPyTorch and dependencies
- Verify GPU access

### Step 3: Test installation

```bash
./test_h100_setup.sh
```

Should show:
```
‚úÖ PyTorch: 2.x.x
‚úÖ GPyTorch: 1.x.x
‚úÖ 2 GPU(s) detected
‚úÖ GPU 0: NVIDIA H100 80GB HBM3
‚úÖ GPU 1: NVIDIA H100 80GB HBM3
‚úÖ ALL TESTS PASSED!
```

## üöÄ Running MOGPR

### Method 1: SLURM Job (Recommended for large datasets)

```bash
# Upload your dataset first
scp combined_dataset.nc username@your_hpc:/path/to/FuseTS/

# Submit job
sbatch run_mogpr_h100.slurm

# Check status
squeue -u $USER

# Monitor GPU usage
watch -n 1 nvidia-smi

# View output
tail -f mogpr_*.out
```

### Method 2: Interactive Session (For testing)

```bash
# Request GPU node
srun --gres=gpu:1 --mem=64G --time=01:00:00 --pty bash

# Activate environment
source ~/mogpr_h100_env/bin/activate  # or: conda activate mogpr_h100

# Run Python
python3
```

Then in Python:

```python
import torch
from fusets.mogpr_gpu import MOGPRTransformerGPU
import xarray as xr

# Load data
ds = xr.open_dataset('combined_dataset.nc')

# Initialize MOGPR
device = torch.device("cuda:0")
mogpr = MOGPRTransformerGPU(device=device, batch_size=512)

# Process
fused = mogpr.fit_transform(ds)

# Save
fused.to_netcdf('fused_result.nc')
```

## ‚ö° Performance Estimates

With 1x H100 80GB:

| Dataset Size | Pixels | Expected Time | Speedup vs CPU |
|--------------|--------|---------------|----------------|
| Test (50√ó50) | 2,500 | 10-20 sec | 30-60x |
| Demak (360√ó800) | 288,000 | 10-15 min | 80-120x |
| Java Island | ~30M | 2-4 hours | 100-200x |
| Full Indonesia | ~200M | 1-2 days | 100-200x |

## üîß Troubleshooting

### Issue: "CUDA out of memory"

Reduce batch size in the SLURM script:

```python
BATCH_SIZE = 256  # Reduce from 512
```

Or process in chunks.

### Issue: "No module named 'fusets.mogpr_gpu'"

Make sure you're in the FuseTS directory:

```bash
cd /path/to/FuseTS
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
```

### Issue: Job fails silently

Check error log:

```bash
cat mogpr_*.err
```

Check GPU availability:

```bash
squeue -u $USER
nvidia-smi
```

### Issue: "torch.cuda.is_available() returns False"

Verify CUDA installation:

```bash
nvcc --version
nvidia-smi
```

Reinstall PyTorch:

```bash
pip install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

## üìä Monitoring

### During job execution:

```bash
# Watch GPU usage
watch -n 1 nvidia-smi

# View live output
tail -f mogpr_*.out

# Check job status
squeue -u $USER

# Check job details
scontrol show job <job_id>
```

### GPU Memory Usage:

```bash
nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv -l 1
```

## üìÅ File Structure

```
FuseTS/
‚îú‚îÄ‚îÄ src/fusets/
‚îÇ   ‚îú‚îÄ‚îÄ mogpr.py              # Original CPU version
‚îÇ   ‚îî‚îÄ‚îÄ mogpr_gpu.py          # GPU-accelerated version
‚îú‚îÄ‚îÄ setup_h100_mogpr.sh       # Installation script
‚îú‚îÄ‚îÄ test_h100_setup.sh        # Test script
‚îú‚îÄ‚îÄ run_mogpr_h100.slurm      # SLURM job script
‚îú‚îÄ‚îÄ combined_dataset.nc       # Your input data (upload this)
‚îî‚îÄ‚îÄ fused_result_*.nc         # Output (created by job)
```

## üéØ Optimization Tips

### 1. Batch Size

H100 has 80GB VRAM - use it!

- Small datasets (<10K pixels): `batch_size=128`
- Medium datasets (10K-100K): `batch_size=256`  
- Large datasets (>100K): `batch_size=512` or higher

### 2. Data Loading

Use chunked loading for huge datasets:

```python
ds = xr.open_dataset('data.nc', chunks={'t': 10, 'y': 100, 'x': 100})
```

### 3. Multi-GPU (Future)

Currently uses 1 GPU. For 2 GPUs, split dataset spatially:

```python
# GPU 0: Process first half
ds_half1 = ds.isel(y=slice(0, n_y//2))

# GPU 1: Process second half  
ds_half2 = ds.isel(y=slice(n_y//2, n_y))
```

## üìà Expected Workflow

1. **Development** (Google Colab CPU):
   - Data preparation
   - Small subset testing
   - Code debugging

2. **Production** (HPC H100):
   - Full dataset processing
   - Batch jobs
   - Large-scale analysis

3. **Analysis** (Local):
   - Download results
   - Visualization
   - Report generation

## üîó Useful Commands

```bash
# Check SLURM job history
sacct -u $USER --format=JobID,JobName,State,Elapsed,MaxRSS

# Cancel job
scancel <job_id>

# Check available partitions
sinfo

# Check your quota
df -h ~

# Transfer files from HPC
scp username@hpc:/path/to/fused_result.nc ~/Downloads/
```

## üìû Support

If you encounter issues:

1. Check the error log: `cat mogpr_*.err`
2. Run test script: `./test_h100_setup.sh`
3. Verify GPU access: `nvidia-smi`
4. Check SLURM logs: `sacct -j <job_id>`

## üéâ Success Criteria

You'll know it's working when you see:

```
‚úÖ GPUs detected: 2
   GPU 0: NVIDIA H100 80GB HBM3
   GPU 1: NVIDIA H100 80GB HBM3

üöÄ Running MOGPR fusion...
Expected time: ~10-15 minutes

[Progress updates...]

‚úÖ MOGPR fusion completed!
   Processing time: 12.3 minutes
   Speed: 23,414 pixels/second
   Peak GPU 0 memory: 45.2 GB

üíæ Saved! File size: 2.4 GB
```

---

**Created**: November 2025  
**System**: 2x NVIDIA H100 80GB HBM3, CUDA 12.4  
**Performance**: 80-120x faster than CPU
