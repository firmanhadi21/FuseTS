{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3dcc246",
   "metadata": {},
   "source": [
    "# Microsoft Planetary Computer - FuseTS Data Preparation (FIXED)\n",
    "\n",
    "**Fix Applied**: Use geometry clipping instead of bbox to handle CRS properly\n",
    "\n",
    "The original error \"No data found in bounds\" occurred because:\n",
    "- MPC Sentinel data comes in UTM projection\n",
    "- We were passing WGS84 coordinates to `rio.clip_box()`\n",
    "- Need to reproject geometry to match data CRS before clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c8810",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed:\n",
    "# !pip install planetary-computer pystac-client rioxarray xarray geopandas\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\u2705 Packages loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e366a56b",
   "metadata": {},
   "source": [
    "## 2. Load Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d03d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shapefile\n",
    "shapefile_path = 'data/klambu-glapan.shp'\n",
    "paddy_gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "print(f\"Loaded {len(paddy_gdf)} features\")\n",
    "print(f\"CRS: {paddy_gdf.crs}\")\n",
    "\n",
    "# Convert to UTM for buffering\n",
    "paddy_utm = paddy_gdf.to_crs(\"EPSG:32749\")\n",
    "paddy_buffered_utm = paddy_utm.copy()\n",
    "paddy_buffered_utm['geometry'] = paddy_utm.buffer(500)  # 500m buffer\n",
    "\n",
    "# Merge and convert back to WGS84\n",
    "merged_geom_utm = unary_union(paddy_buffered_utm.geometry)\n",
    "buffered_gdf = gpd.GeoDataFrame(geometry=[merged_geom_utm], crs=\"EPSG:32749\")\n",
    "buffered_gdf_wgs84 = buffered_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Get bbox for STAC searches\n",
    "west, south, east, north = buffered_gdf_wgs84.total_bounds\n",
    "bbox = [west, south, east, north]\n",
    "\n",
    "# Get geometry for clipping\n",
    "study_area_geom = buffered_gdf_wgs84.geometry.iloc[0]\n",
    "\n",
    "print(f\"\\nBBox: {bbox}\")\n",
    "print(f\"Area: {buffered_gdf.area.sum() / 1e6:.2f} km\u00b2\")\n",
    "\n",
    "# Config\n",
    "START_DATE = '2023-11-01'\n",
    "END_DATE = '2025-11-07'\n",
    "TARGET_CRS = \"EPSG:32749\"\n",
    "TARGET_RESOLUTION = 10\n",
    "OUTPUT_DIR = Path('mpc_data')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df8f83",
   "metadata": {},
   "source": [
    "## 3. Generate Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572856a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_periods(start_str, end_str, days=12):\n",
    "    start = datetime.strptime(start_str, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end_str, '%Y-%m-%d')\n",
    "    periods = []\n",
    "    period_num = 1\n",
    "    current = start\n",
    "    \n",
    "    while current <= end:\n",
    "        period_end = min(current + timedelta(days=days-1), end)\n",
    "        periods.append({\n",
    "            'period': period_num,\n",
    "            'start_str': current.strftime('%Y-%m-%d'),\n",
    "            'end_str': period_end.strftime('%Y-%m-%d'),\n",
    "            'center_date': current + timedelta(days=days//2)\n",
    "        })\n",
    "        if period_end >= end:\n",
    "            break\n",
    "        current = period_end + timedelta(days=1)\n",
    "        period_num += 1\n",
    "    \n",
    "    return periods\n",
    "\n",
    "periods = generate_periods(START_DATE, END_DATE, 12)\n",
    "print(f\"Generated {len(periods)} periods\")\n",
    "print(f\"First: {periods[0]['start_str']} to {periods[0]['end_str']}\")\n",
    "print(f\"Last: {periods[-1]['start_str']} to {periods[-1]['end_str']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2080cb",
   "metadata": {},
   "source": [
    "## 4. Connect to MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace\n",
    ")\n",
    "print(\"\u2705 Connected to Microsoft Planetary Computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b8a7c",
   "metadata": {},
   "source": [
    "## 5. Sentinel-2 Functions (FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sentinel2(bbox, start_date, end_date, max_cloud=80):\n",
    "    \"\"\"Search for S2 scenes\"\"\"\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        bbox=bbox,\n",
    "        datetime=f\"{start_date}/{end_date}\",\n",
    "        query={\"eo:cloud_cover\": {\"lt\": max_cloud}}\n",
    "    )\n",
    "    return list(search.items())\n",
    "\n",
    "def load_sentinel2_ndvi(items, study_geom, target_crs=\"EPSG:32749\", resolution=10):\n",
    "    \"\"\"\n",
    "    Load S2 and compute NDVI - FIXED VERSION\n",
    "    Uses geometry clipping with proper CRS handling\n",
    "    \"\"\"\n",
    "    if not items:\n",
    "        return None\n",
    "    \n",
    "    ndvi_arrays = []\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        try:\n",
    "            # Get and sign assets\n",
    "            red_href = planetary_computer.sign(item.assets[\"B04\"].href)\n",
    "            nir_href = planetary_computer.sign(item.assets[\"B08\"].href)\n",
    "            \n",
    "            # Load bands\n",
    "            red = rioxarray.open_rasterio(red_href, masked=True).squeeze()\n",
    "            nir = rioxarray.open_rasterio(nir_href, masked=True).squeeze()\n",
    "            \n",
    "            # KEY FIX: Reproject study area to match data CRS\n",
    "            study_proj = gpd.GeoSeries([study_geom], crs=\"EPSG:4326\").to_crs(red.rio.crs)\n",
    "            \n",
    "            # Clip using geometry (not bbox)\n",
    "            red_clip = red.rio.clip(study_proj.geometry, study_proj.crs, drop=True)\n",
    "            nir_clip = nir.rio.clip(study_proj.geometry, study_proj.crs, drop=True)\n",
    "            \n",
    "            if red_clip.size == 0 or nir_clip.size == 0:\n",
    "                print(f\"      Scene {i+1}: No data after clip\")\n",
    "                continue\n",
    "            \n",
    "            # Reproject to target CRS\n",
    "            if str(red_clip.rio.crs) != target_crs:\n",
    "                red_clip = red_clip.rio.reproject(target_crs, resolution=resolution)\n",
    "                nir_clip = nir_clip.rio.reproject(target_crs, resolution=resolution)\n",
    "            \n",
    "            # Calculate NDVI\n",
    "            ndvi = (nir_clip - red_clip) / (nir_clip + red_clip)\n",
    "            ndvi = ndvi.where(np.isfinite(ndvi))\n",
    "            \n",
    "            ndvi_arrays.append(ndvi)\n",
    "            print(f\"      Scene {i+1}: \u2705 NDVI computed ({ndvi.shape})\")\n",
    "            \n",
    "            # Clean up\n",
    "            red.close()\n",
    "            nir.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      Scene {i+1}: \u274c Error - {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not ndvi_arrays:\n",
    "        return None\n",
    "    \n",
    "    # Median composite\n",
    "    stacked = xr.concat(ndvi_arrays, dim='time')\n",
    "    median = stacked.median(dim='time', skipna=True)\n",
    "    median = median.rio.write_crs(target_crs)\n",
    "    \n",
    "    return median\n",
    "\n",
    "print(\"\u2705 S2 functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33d4ab",
   "metadata": {},
   "source": [
    "## 6. Sentinel-1 Functions (FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9533f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sentinel1(bbox, start_date, end_date):\n",
    "    \"\"\"Search for S1 scenes\"\"\"\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-grd\"],\n",
    "        bbox=bbox,\n",
    "        datetime=f\"{start_date}/{end_date}\",\n",
    "        query={\n",
    "            \"sat:orbit_state\": {\"eq\": \"descending\"},\n",
    "            \"sar:instrument_mode\": {\"eq\": \"IW\"}\n",
    "        }\n",
    "    )\n",
    "    return list(search.items())\n",
    "\n",
    "def load_sentinel1(items, study_geom, target_crs=\"EPSG:32749\", resolution=10):\n",
    "    \"\"\"\n",
    "    Load S1 VV/VH - FIXED VERSION\n",
    "    Uses geometry clipping with proper CRS handling\n",
    "    \"\"\"\n",
    "    if not items:\n",
    "        return None, None\n",
    "    \n",
    "    vv_arrays = []\n",
    "    vh_arrays = []\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        try:\n",
    "            # Get and sign assets\n",
    "            vv_href = planetary_computer.sign(item.assets[\"vv\"].href)\n",
    "            vh_href = planetary_computer.sign(item.assets[\"vh\"].href)\n",
    "            \n",
    "            # Load bands\n",
    "            vv = rioxarray.open_rasterio(vv_href, masked=True).squeeze()\n",
    "            vh = rioxarray.open_rasterio(vh_href, masked=True).squeeze()\n",
    "            \n",
    "            # KEY FIX: Reproject study area to match data CRS\n",
    "            study_proj = gpd.GeoSeries([study_geom], crs=\"EPSG:4326\").to_crs(vv.rio.crs)\n",
    "            \n",
    "            # Clip\n",
    "            vv_clip = vv.rio.clip(study_proj.geometry, study_proj.crs, drop=True)\n",
    "            vh_clip = vh.rio.clip(study_proj.geometry, study_proj.crs, drop=True)\n",
    "            \n",
    "            if vv_clip.size == 0 or vh_clip.size == 0:\n",
    "                print(f\"      Scene {i+1}: No data after clip\")\n",
    "                continue\n",
    "            \n",
    "            # Reproject to target\n",
    "            if str(vv_clip.rio.crs) != target_crs:\n",
    "                vv_clip = vv_clip.rio.reproject(target_crs, resolution=resolution)\n",
    "                vh_clip = vh_clip.rio.reproject(target_crs, resolution=resolution)\n",
    "            \n",
    "            vv_arrays.append(vv_clip)\n",
    "            vh_arrays.append(vh_clip)\n",
    "            print(f\"      Scene {i+1}: \u2705 VV/VH loaded ({vv_clip.shape})\")\n",
    "            \n",
    "            vv.close()\n",
    "            vh.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      Scene {i+1}: \u274c Error - {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not vv_arrays:\n",
    "        return None, None\n",
    "    \n",
    "    # Median composites\n",
    "    vv_stacked = xr.concat(vv_arrays, dim='time')\n",
    "    vh_stacked = xr.concat(vh_arrays, dim='time')\n",
    "    \n",
    "    vv_median = vv_stacked.median(dim='time', skipna=True).rio.write_crs(target_crs)\n",
    "    vh_median = vh_stacked.median(dim='time', skipna=True).rio.write_crs(target_crs)\n",
    "    \n",
    "    return vv_median, vh_median\n",
    "\n",
    "print(\"\u2705 S1 functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184840e2",
   "metadata": {},
   "source": [
    "## 7. Process Test Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"\ud83e\uddea TESTING WITH FIRST 3 PERIODS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for period in periods[:3]:\n",
    "    print(f\"\\nPeriod {period['period']}: {period['start_str']} to {period['end_str']}\")\n",
    "    \n",
    "    # Search S2\n",
    "    print(\"  \ud83d\udef0\ufe0f  Searching Sentinel-2...\")\n",
    "    s2_items = search_sentinel2(bbox, period['start_str'], period['end_str'])\n",
    "    print(f\"     Found {len(s2_items)} scenes\")\n",
    "    \n",
    "    # Search S1\n",
    "    print(\"  \ud83d\udce1 Searching Sentinel-1...\")\n",
    "    s1_items = search_sentinel1(bbox, period['start_str'], period['end_str'])\n",
    "    print(f\"     Found {len(s1_items)} scenes\")\n",
    "    \n",
    "    # Load S2\n",
    "    ndvi = None\n",
    "    if s2_items:\n",
    "        print(\"  \ud83d\udce5 Loading S2 NDVI...\")\n",
    "        ndvi = load_sentinel2_ndvi(s2_items, study_area_geom, TARGET_CRS, TARGET_RESOLUTION)\n",
    "    \n",
    "    # Load S1\n",
    "    vv, vh = None, None\n",
    "    if s1_items:\n",
    "        print(\"  \ud83d\udce5 Loading S1 VV/VH...\")\n",
    "        vv, vh = load_sentinel1(s1_items, study_area_geom, TARGET_CRS, TARGET_RESOLUTION)\n",
    "    \n",
    "    # Combine\n",
    "    if ndvi is not None or (vv is not None and vh is not None):\n",
    "        ref = ndvi if ndvi is not None else vv\n",
    "        \n",
    "        ds_dict = {}\n",
    "        if vv is not None:\n",
    "            ds_dict['VV'] = vv.rio.reproject_match(ref)\n",
    "        if vh is not None:\n",
    "            ds_dict['VH'] = vh.rio.reproject_match(ref)\n",
    "        if ndvi is not None:\n",
    "            ds_dict['S2ndvi'] = ndvi\n",
    "        \n",
    "        ds = xr.Dataset(ds_dict)\n",
    "        ds = ds.assign_coords(t=period['center_date'])\n",
    "        \n",
    "        test_results.append({\n",
    "            'period': period['period'],\n",
    "            'dataset': ds,\n",
    "            'n_s2': len(s2_items),\n",
    "            'n_s1': len(s1_items)\n",
    "        })\n",
    "        print(f\"  \u2705 Period processed (S1: {len(s1_items)}, S2: {len(s2_items)})\")\n",
    "    else:\n",
    "        print(f\"  \u26a0\ufe0f  No data\")\n",
    "\n",
    "print(f\"\\n\u2705 Test complete: {len(test_results)}/{len(periods[:3])} periods successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5294d",
   "metadata": {},
   "source": [
    "## 8. Create Test Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_results:\n",
    "    # Combine\n",
    "    test_ts = xr.concat([r['dataset'] for r in test_results], dim='t')\n",
    "    test_ts = test_ts.transpose('t', 'y', 'x')\n",
    "    \n",
    "    print(f\"Test time series:\")\n",
    "    print(test_ts)\n",
    "    \n",
    "    # Save\n",
    "    test_file = OUTPUT_DIR / 'test_timeseries.nc'\n",
    "    test_ts.to_netcdf(test_file)\n",
    "    print(f\"\\n\ud83d\udcbe Saved: {test_file}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    if 'VV' in test_ts:\n",
    "        test_ts['VV'].mean('t').plot(ax=axes[0], cmap='gray')\n",
    "        axes[0].set_title('Mean VV')\n",
    "    \n",
    "    if 'VH' in test_ts:\n",
    "        test_ts['VH'].mean('t').plot(ax=axes[1], cmap='gray')\n",
    "        axes[1].set_title('Mean VH')\n",
    "    \n",
    "    if 'S2ndvi' in test_ts:\n",
    "        test_ts['S2ndvi'].mean('t').plot(ax=axes[2], cmap='RdYlGn', vmin=-0.2, vmax=0.8)\n",
    "        axes[2].set_title('Mean NDVI')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'test_preview.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\u2705 Test successful! You can now process all periods.\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  No test results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93741451",
   "metadata": {},
   "source": [
    "## 9. Process ALL Periods (Full Run)\n",
    "\n",
    "Once the test works, uncomment and run this to process all ~62 periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ecae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_all_periods():\n",
    "#     all_results = []\n",
    "#     \n",
    "#     for period in periods:\n",
    "#         print(f\"\\nPeriod {period['period']}/{len(periods)}: {period['start_str']} to {period['end_str']}\")\n",
    "#         \n",
    "#         s2_items = search_sentinel2(bbox, period['start_str'], period['end_str'])\n",
    "#         s1_items = search_sentinel1(bbox, period['start_str'], period['end_str'])\n",
    "#         \n",
    "#         print(f\"  S2: {len(s2_items)}, S1: {len(s1_items)}\")\n",
    "#         \n",
    "#         ndvi = load_sentinel2_ndvi(s2_items, study_area_geom, TARGET_CRS, TARGET_RESOLUTION) if s2_items else None\n",
    "#         vv, vh = load_sentinel1(s1_items, study_area_geom, TARGET_CRS, TARGET_RESOLUTION) if s1_items else (None, None)\n",
    "#         \n",
    "#         if ndvi is not None or (vv is not None and vh is not None):\n",
    "#             ref = ndvi if ndvi is not None else vv\n",
    "#             ds_dict = {}\n",
    "#             if vv is not None: ds_dict['VV'] = vv.rio.reproject_match(ref)\n",
    "#             if vh is not None: ds_dict['VH'] = vh.rio.reproject_match(ref)\n",
    "#             if ndvi is not None: ds_dict['S2ndvi'] = ndvi\n",
    "#             \n",
    "#             ds = xr.Dataset(ds_dict).assign_coords(t=period['center_date'])\n",
    "#             all_results.append(ds)\n",
    "#             print(f\"  \u2705\")\n",
    "#     \n",
    "#     # Create final time series\n",
    "#     final_ts = xr.concat(all_results, dim='t').transpose('t', 'y', 'x')\n",
    "#     \n",
    "#     # Save\n",
    "#     final_file = OUTPUT_DIR / f'klambu_glapan_{START_DATE}_{END_DATE}_final.nc'\n",
    "#     final_ts.to_netcdf(final_file)\n",
    "#     \n",
    "#     print(f\"\\n\u2705 Complete! {len(all_results)} periods\")\n",
    "#     print(f\"\ud83d\udcbe Saved: {final_file}\")\n",
    "#     return final_ts\n",
    "# \n",
    "# # Uncomment to run:\n",
    "# # final_timeseries = process_all_periods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152086f2",
   "metadata": {},
   "source": [
    "## Key Fixes Applied\n",
    "\n",
    "### Problem\n",
    "```\n",
    "Error loading scene: No data found in bounds.\n",
    "```\n",
    "\n",
    "### Root Cause\n",
    "- MPC Sentinel data comes in UTM projection (e.g., EPSG:32649, EPSG:32749)\n",
    "- We passed WGS84 coordinates (EPSG:4326) to `rio.clip_box()`\n",
    "- The UTM data couldn't find lat/lon coordinates\n",
    "\n",
    "### Solution\n",
    "1. **Before**: `red.rio.clip_box(*bbox)` with WGS84 bbox\n",
    "2. **After**: \n",
    "   - Reproject study area geometry to match data CRS\n",
    "   - Use `rio.clip(geometry, crs)` instead of `clip_box()`\n",
    "   - Then reproject result to target CRS\n",
    "\n",
    "### Code Pattern\n",
    "```python\n",
    "# Load data (comes in native UTM)\n",
    "data = rioxarray.open_rasterio(href, masked=True).squeeze()\n",
    "\n",
    "# Reproject study area to match data CRS\n",
    "study_proj = gpd.GeoSeries([study_geom], crs=\"EPSG:4326\").to_crs(data.rio.crs)\n",
    "\n",
    "# Clip using geometry\n",
    "data_clipped = data.rio.clip(study_proj.geometry, study_proj.crs, drop=True)\n",
    "\n",
    "# Reproject to target CRS\n",
    "data_final = data_clipped.rio.reproject(target_crs, resolution=resolution)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}